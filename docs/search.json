[
  {
    "objectID": "biostatistics.html",
    "href": "biostatistics.html",
    "title": "Biostatistics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nKaplan Meir Plots in Python\n\n\nAn Experiment to see if I can produce Kaplan Meir plots using Python\n\n\n\n\n\n30 May, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMSc Epidemiology: Thesis\n\n\nA Retrospective Analysis of German Non‚ÄêSpecific Lower Back Pain Patients and their Patient Pathway Before and After Emergency Department Treatment\n\n\n\n\n\n1 Sep, 2023\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "maps/uk_maps.html",
    "href": "maps/uk_maps.html",
    "title": "UK Population",
    "section": "",
    "text": "1. R code\n\n\nThumbnail\n\n\nShow codeif(!require(tidyverse)){install.packages(\"tidyverse\");library(tidyverse)}\nif(!require(ggplot2)){install.packages(\"ggplot2\");library(ggplot2)}\nif(!require(ggrepel)){install.packages(\"ggrepel\");library(ggrepel)}\nif(!require(sf)){install.packages(\"sf\");library(sf)}\nif(!require(eurostat)){install.packages(\"eurostat\");library(eurostat)}\nif(!require(classInt)){install.packages(\"classInt\");library(classInt)}\nif(!require(giscoR)){install.packages(\"giscoR\");library(giscoR)}\nif(!require(cartogram)){install.packages(\"cartogram\");library(cartogram)}\nif(!require(rayshader)){install.packages(\"rayshader\");library(rayshader)}\nif(!require(sysfonts)){install.packages(\"sysfonts\");library(sysfonts)}\nif(!require(showtext)){install.packages(\"showtext\");library(showtext)}\n\n# Define Fonts \n\n\nsysfonts::font_add_google(\"Roboto Mono\")\nshowtext::showtext_auto()\n\nget_polygon &lt;- function() {\n  # st_area returns square meters so we get square km by dividing the result by 1000\n  df$area_sqkm &lt;- as.numeric(sf::st_area(df) / 1000000)\n  \n  deu_polygon &lt;- df |&gt;\n    dplyr::mutate(pop_per_sqr_km = values / area_sqkm)\n  return(deu_polygon)\n}\n\ncustom_theme &lt;- function() {\n  theme_minimal() +\n    theme(\n      text = element_text(size = 12),\n      axis.line = element_blank(),\n      axis.text.x = element_blank(),\n      axis.text.y = element_blank(),\n      axis.ticks = element_blank(),\n      axis.title.y = element_blank(),\n      legend.position =  \"bottom\",\n      legend.text = element_text(size = 30, color = \"grey20\"),\n      legend.title = element_text(size = 40, color = \"grey20\"),\n      legend.spacing.y = unit(0.25, \"cm\"),\n      legend.spacing.x = unit(0.25, \"cm\"),\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank(),\n      plot.margin = unit(\n        c(t = 0, r = 0, b = 0, l = 0), \"lines\"\n      ),\n      plot.background = element_rect(fill = \"#f5f5f2\", color = NA),\n      panel.background = element_rect(fill = \"#f5f5f2\", color = NA),\n      legend.background = element_rect(fill = \"#f5f5f2\", color = NA),\n      panel.border = element_blank(),\n    )\n}\n\n# colors\ncols &lt;- rev(c(\n  \"#004225\", \"#2e8b57\",\n  \"#4682b4\", \"#5f9ea0\",\n  \"#20b2aa\", \"#008b8b\",\n  \"#b0e0e6\"\n))\n\n\n\nmake_polygon_map &lt;- function(polygon, theme) {\n  p1 &lt;-\n    ggplot(polygon) +\n    geom_sf(aes(fill = pop_per_sqr_km),\n            color = \"grey20\",\n            size = .1\n    ) +\n    scale_fill_gradientn(\n      name = \"\",\n      colours = cols,\n      breaks = breaks,\n      labels = round(breaks, 0),\n      limits = c(vmin, vmax)\n    ) +\n    guides(fill = guide_legend(\n      direction = \"horizontal\",\n      keyheight = unit(1.15, units = \"mm\"),\n      keywidth = unit(15, units = \"mm\"),\n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = .5,\n      nrow = 1,\n      byrow = T,\n      reverse = F,\n      label.position = \"bottom\"\n    )) +\n    theme() +\n    labs(\n      y = \"\",\n      subtitle = \"\",\n      x = \"\",\n      title = \"\",\n      caption = \"\"\n    )\n  return(p1)\n}\n\n\n# Label Regions -----------------------------------------------------------\n\nlabel_regions &lt;- function(coordinates) {\n  ggrepel::geom_text_repel(coordinates[1:5, ],\n                           mapping = aes(x = long, y = lat, label = NAME_LATN),\n                           colour = \"grey20\",\n                           fontface = \"bold\",\n                           size = 10,\n                           segment.colour = \"grey20\",\n                           segment.alpha = .9,\n                           segment.linetype = 3,\n                           segment.size = .25,\n                           nudge_x = .95,\n                           nudge_y = .15,\n                           direction = \"x\"\n  )\n}\n\n\n\n\n\nmake_point_map &lt;- function(coordinates, labels) {\n  p2 &lt;-\n    ggplot() +\n    geom_sf(\n      data = polygon,\n      fill = \"transparent\",\n      color = \"grey20\",\n      size = .1\n    ) +\n    geom_sf(\n      data = points,\n      mapping = aes(\n        size = pop_1000s,\n        geometry = geometry\n      ), color = cols[5],\n      alpha = .5\n    ) +\n    scale_size(\n      breaks = breaks,\n      range = c(1, 10),\n      labels = round(breaks, 0),\n      limits = c(vmin, vmax),\n      name = \"\"\n    ) +\n    guides(\n      color = \"none\",\n      size = guide_legend(\n        direction = \"vertical\",\n        title.position = \"top\",\n        title.hjust = 0.5,\n        label.hjust = 0,\n        nrow = 1,\n        byrow = F,\n        reverse = F,\n        label.position = \"bottom\"\n      )\n    ) +\n    custom_theme() +\n    labs(\n      y = \"\",\n      subtitle = \"\",\n      x = \"\",\n      title = \"\",\n      caption = \"\"\n    )\n  \n  # Add label regions only if labels = TRUE\n  if (labels) {\n    p2 &lt;- p2 + label_regions(coordinates)\n  }\n  \n  return(p2)\n}\n\n\nget_cartogram &lt;- function(df) {\n  deu_cart &lt;- df %&gt;% \n    sf::st_transform(crs = crsLAEA) |&gt;\n    cartogram::cartogram_cont(\n      weight = \"pop_1000s\",\n      itermax = 5\n    ) |&gt;\n    sf::st_transform(crs = crsLONGLAT)\n  return(deu_cart)\n}\n\n\nmake_cartogram &lt;- function(cart, coordinates, labels) {\n  p3a &lt;-\n    ggplot(cart) +\n    geom_sf(aes(fill = pop_1000s),\n            color = \"grey20\",\n            size = .1\n    ) +\n    scale_fill_gradientn(\n      name = \"\",\n      colours = cols,\n      breaks = breaks,\n      labels = round(breaks, 0),\n      limits = c(vmin, vmax)\n    ) +\n    guides(fill = guide_legend(\n      direction = \"horizontal\",\n      keyheight = unit(1.15, units = \"mm\"),\n      keywidth = unit(15, units = \"mm\"),\n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = .5,\n      nrow = 1,\n      byrow = T,\n      reverse = F,\n      label.position = \"bottom\"\n    )) +\n    custom_theme() +\n    labs(\n      y = \"\",\n      subtitle = \"\",\n      x = \"\",\n      title = \"\",\n      caption = \"\"\n    )\n  \n  # Add label regions only if labels = TRUE\n  if (labels) {\n    p3a &lt;- p3a + label_regions(coordinates)\n  }\n  \n  return(p3a)\n}\n\n\nget_ncontig_cartogram &lt;- function(data) {\n  deu_ncart &lt;- data %&gt;% \n    sf::st_transform(crs = crsLAEA) %&gt;% \n    cartogram::cartogram_ncont(\n      weight = \"pop_1000s\",\n      inplace = F\n    )\n  return(deu_ncart)\n}\n\n\n\n\n\nmake_ncontig_cartogram &lt;- function(ncart, nuts, theme) {\n  p3b &lt;-\n    ggplot(ncart) +\n    geom_sf(aes(fill = pop_1000s),\n            color = NA,\n            size = 0\n    ) +\n    geom_sf(\n      data = nuts, fill = \"transparent\",\n      color = \"grey20\", size = .1\n    ) +\n    scale_fill_gradientn(\n      name = \"\",\n      colours = cols,\n      breaks = breaks,\n      labels = round(breaks, 0),\n      limits = c(vmin, vmax)\n    ) +\n    guides(fill = guide_legend(\n      position = \"bottom\",\n      direction = \"horizontal\",\n      keyheight = unit(1.15, units = \"mm\"),\n      keywidth = unit(15, units = \"mm\"),\n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = .5,\n      nrow = 1,\n      byrow = T,\n      reverse = F,\n      label.position = \"bottom\"\n    )) +\n    theme() +\n    labs(\n      y = \"\",\n      subtitle = \"\",\n      x = \"\",\n      title = \"\",\n      caption = \"\"\n    )\n  return(p3b)\n}\n\nget_dorling_cartogram &lt;- function(data) {\n  dorling_cart &lt;- data %&gt;% \n    filter(!is.na(values)) %&gt;% \n    st_transform(crs = crsLAEA) %&gt;% \n    cartogram::cartogram_dorling(\n      weight = \"pop_1000s\"\n    )\n  return(dorling_cart)\n}\n\n\n\nmake_dorling_cartogram &lt;- function(dorling_cart, theme) {\n  p3c &lt;-\n    ggplot(dorling_cart) +\n    geom_sf(aes(fill = pop_1000s),\n            color = NA,\n            size = 0\n    ) +\n    scale_fill_gradientn(\n      name = \"\",\n      colours = cols,\n      breaks = breaks,\n      labels = round(breaks, 0),\n      limits = c(vmin, vmax)\n    ) +\n    guides(fill = guide_legend(\n      position = , \"bottom\",\n      direction = \"horizontal\",\n      keyheight = unit(1.15, units = \"mm\"),\n      keywidth = unit(15, units = \"mm\"),\n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = .5,\n      nrow = 1,\n      byrow = T,\n      reverse = F,\n      label.position = \"bottom\"\n    )) +\n    theme() +\n    labs(\n      y = \"\",\n      subtitle = \"\",\n      x = \"\",\n      title = \"\",\n      caption = \"\"\n    )\n  return(p3c)\n}\n\n\n\nget_dot_density &lt;- function(data) {\n  num_dots &lt;- ceiling(dplyr::select(as.data.frame(data), pop_1000s)) %&gt;% \n    filter(!is.na(pop_1000s))\n  dots &lt;- map_df(\n    names(num_dots),\n    ~ sf::st_sample(df, size = num_dots[, .x], type = \"random\") %&gt;% \n      sf::st_cast(\"POINT\") %&gt;% \n      sf::st_coordinates() %&gt;% \n      as_tibble() %&gt;% \n      setNames(c(\"long\", \"lat\"))\n  )\n  return(dots)\n}\n\nmake_dot_density_map &lt;- function(dots, nuts, labels, coordinates, theme) {\n  p4 &lt;-\n    ggplot(dots) +\n    geom_sf(\n      data = nuts, fill = \"transparent\",\n      color = \"grey20\", size = .1\n    ) +\n    geom_point(\n      data = dots, aes(x = long, y = lat),\n      color = cols[5], size = .1, shape = 19, alpha = .2\n    ) +\n    theme() +\n    labs(\n      y = \"\",\n      subtitle = \"\",\n      x = \"\",\n      title = \"\",\n      caption = \"\"\n    )\n  \n  # Add label regions only if labels = TRUE\n  if (labels) {\n    p4 &lt;- p4 + label_regions(coordinates)\n  }\n  \n  \n  return(p4)\n}\n\nget_grid &lt;- function(country) {\n  \n  sf &lt;- giscoR::gisco_get_countries(\n    year = \"2020\",\n    epsg = \"4326\",\n    resolution = \"3\",\n    country = country\n  )\n  \n  sf_transf &lt;- sf |&gt;\n    sf::st_transform(3575)\n  \n  grid &lt;- sf_transf |&gt;\n    sf::st_make_grid(cellsize = 50000) |&gt;\n    sf::st_intersection(sf_transf) |&gt;\n    st_cast(\"MULTIPOLYGON\") |&gt;\n    sf::st_sf() |&gt;\n    dplyr::mutate(id = row_number()) |&gt;\n    sf::st_transform(crs = crsLONGLAT)\n  \n  \n  return(grid)\n}\n\n\nget_aggregated_grid &lt;- function(grid, points) {\n  grid_final &lt;- grid %&gt;% \n    sf::st_join(points) %&gt;% \n    dplyr::group_by(id) %&gt;% \n    dplyr::summarise_at(\n      vars(pop_1000s),\n      list(pop_sum = sum)\n    ) %&gt;% \n    drop_na(pop_sum) %&gt;% \n    sf::st_sf() %&gt;% \n    sf::st_transform(crs = crsLONGLAT)\n  return(grid_final)\n}\n\n\n\nmake_grid_map &lt;- function(data, coordinates, labels, theme) {\n  p5 &lt;-\n    ggplot(data) +\n    geom_sf(aes(fill = pop_sum),\n            color = \"grey20\",\n            size = .1\n    ) +\n    scale_fill_gradientn(\n      name = \"\",\n      colours = cols,\n      breaks = breaks,\n      labels = round(breaks, 0),\n      limits = c(vmin, vmax)\n    ) +\n    guides(fill = guide_legend(\n      direction = \"horizontal\",\n      keyheight = unit(1.15, units = \"mm\"),\n      keywidth = unit(15, units = \"mm\"),\n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = .5,\n      nrow = 1,\n      byrow = T,\n      reverse = F,\n      label.position = \"bottom\"\n    )) +\n    theme() +\n    labs(\n      y = \"\",\n      subtitle = \"\",\n      x = \"\",\n      title = \"\",\n      caption = \"\"\n    )\n  return(p5)\n  \n  # Add label regions only if labels = TRUE\n  if (labels) {\n    p5 &lt;- p5 + label_regions(coordinates)\n  }\n  \n}\n\n\nmake_raster_matrix &lt;- function(data) {\n  pop_rast &lt;- terra::rasterize(\n    data,\n    terra::rast(data, resolution = .01),\n    data$pop_sum\n  ) %&gt;%  terra::na.omit()\n  \n  pop_mat &lt;- rayshader::raster_to_matrix(pop_rast)\n  \n  return(pop_mat)\n}\n\n\n# Defining LongLat --------------------------------------------------------\n\n# longlat\ncrsLONGLAT &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n# Lambert\ncrsLAEA &lt;-  \"+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs\"\n\ncountry = \"UK\"\n\n# Get  internal boundaries ---------------------------------\n\n\nnuts3 &lt;- giscoR::gisco_get_nuts(\n  year = \"2021\",\n  epsg = \"4326\",\n  resolution = \"3\",\n  nuts_level = \"3\",\n  country = country\n)\n\n\n# Get the population data -------------------------------------------------\n\n\npop_df &lt;- eurostat::get_eurostat(\"demo_r_pjangrp3\",\n                                 time_format = \"num\"\n) %&gt;% \n  dplyr::filter(\n    sex == \"T\" &\n      unit == \"NR\" &\n      age == \"TOTAL\" &\n      grepl(\"UK\", geo) &\n      TIME_PERIOD == 2019 # No data available after that - likely due to\n  ) %&gt;% \n  dplyr::select(geo, values) %&gt;% \n  dplyr:: rename(NUTS_ID = geo) # rename for Merge\n\ndf &lt;- nuts3 %&gt;% \n  dplyr::left_join(pop_df, by = \"NUTS_ID\")\n\n\n# Draw the ploygons -------------------------------------------------------\n\npolygon &lt;- get_polygon()\n\nvmin &lt;- min(polygon$pop_per_sqr_km, na.rm = T)\nvmax &lt;- max(polygon$pop_per_sqr_km, na.rm = T)\n\n\nbrk &lt;- round(classIntervals(polygon$pop_per_sqr_km,\n                            n = 6,\n                            style = \"equal\")$brks, 0) %&gt;% \n  head(-1) %&gt;% \n  tail(-1) %&gt;% \n  append(vmax)\n\nbreaks &lt;- c(vmin, brk)\n\n\nmap1 &lt;- make_polygon_map(polygon = polygon, theme = custom_theme) %&gt;% \n  print()\n\n\n\n\n\n\nShow codeggsave(\n  filename = paste0(country, \"_population_polygon.png\"),\n  width = 6, height = 8.5, dpi = 600, device = \"png\",\n  bg = \"#f5f5f2\", map1)\n\n\n# Draw the Points on the Map ----------------------------------------------\n\n\n# normalize population size\ndf$pop_1000s &lt;- df$values / 1000\n\nvmin &lt;- min(df$pop_1000s, na.rm = T)\nvmax &lt;- max(df$pop_1000s, na.rm = T)\n\n# bins\nbrk &lt;- round(classIntervals(df$pop_1000s,\n                            n = 6,\n                            style = \"equal\"\n)$brks, 0) %&gt;% \n  head(-1) %&gt;% \n  tail(-1) %&gt;% \n  append(vmax)\n\n# breaks\nbreaks &lt;- c(vmin, brk)\n\npoints &lt;- df %&gt;% \n  sf::st_centroid()\n\ncoords &lt;- points %&gt;% \n  dplyr::mutate(\n    long = unlist(map(geometry, 1)),\n    lat = unlist(map(geometry, 2))\n  ) %&gt;% \n  dplyr::select(NAME_LATN, long, lat, pop_1000s) %&gt;% \n  sf::st_drop_geometry() %&gt;% \n  as.data.frame() %&gt;% \n  dplyr::arrange(desc(pop_1000s))\n\n#Just want the capitals maps\n\ncities_data &lt;- data.frame(\n  NAME_LATN = c(\"Cardiff\", \"London\", \"Edinburgh\", \"Belfast\"),\n  lat = c(51.4816, 51.5074, 55.9533, 54.5973),\n  long = c(-3.1791, -0.1278, -3.1883, -5.9301)\n)\n\n\n\n\nmap2 &lt;- make_point_map(coordinates= cities_data, labels = T) %&gt;% \n  print()\n\n\n\n\n\n\nShow codeggsave(\n  filename = paste0(country, \"_population_polygon_point.png\"),\n  width = 6, height = 8.5, dpi = 600, device = \"png\",\n  bg = \"white\", map2\n)\n\n\n# Cartogram ---------------------------------------------------------------\n\n\ncart &lt;- get_cartogram(df)\n\nmap3a &lt;- make_cartogram(cart, coordinates= cities_data, labels = T)\n\n\nggsave(\n  filename = paste0(country, \"_population_cartogram.png\"),\n  width = 6, height = 8.5, dpi = 600,\n  device = \"png\", bg = \"white\", map3a\n)\n\n\n# Non-contiguous Area Cartogram -------------------------------------------\n\nncart &lt;- get_ncontig_cartogram(data = df)\n\nmap3b &lt;- make_ncontig_cartogram(ncart = ncart, nuts = nuts3, theme = custom_theme())\n\n\n\n# Dorling -----------------------------------------------------------------\n\n\ndorling_cart &lt;- get_dorling_cartogram(data = df)\n\n\nmap3c &lt;- make_dorling_cartogram(dorling_cart = dorling_cart, theme = custom_theme)\n\n\nggsave(\n  filename = paste0(country, \"_population_dorling_cartogram.png\"),\n  width = 7, height = 7.5, dpi = 600, device = \"png\",\n  bg = \"white\", map3c)\n\n\n# Dot Density -------------------------------------------------------------\n\ndots &lt;- get_dot_density(data = df)\n\n\nmap4 &lt;- make_dot_density_map(dots = dots, nuts = nuts3, labels = T, coordinates = cities_data, theme = custom_theme)\n\n\nggsave(\n  filename = paste0(country, \"_population_dot_density.png\"),\n  width = 6, height = 8.5, dpi = 600, device = \"png\",\n  bg = \"white\", map4\n)\n\ngrid &lt;- get_grid(country = country)\n\n\ngrid_final &lt;- get_aggregated_grid(grid = grid, points = points)\n\n\nvmin &lt;- min(grid_final$pop_sum, na.rm = T)\nvmax &lt;- max(grid_final$pop_sum, na.rm = T)\n\nbrk &lt;- round(classIntervals(grid_final$pop_sum,\n                            n = 6,\n                            style = \"equal\"\n)$brks, 0) %&gt;% \n  head(-1) %&gt;% \n  tail(-1) %&gt;% \n  append(vmax)\n\nbreaks &lt;- c(vmin, brk)\n\n\nmap5 &lt;- make_grid_map(data = grid_final, coordinates = cities_data, labels = T, theme =custom_theme)\n\nggsave(\n  filename = paste0(country, \"_population_grid.png\"),\n  width = 6, height = 8.5, dpi = 600, device = \"png\",\n  bg = \"#f5f5f2\", map5\n)\n\npop_mat &lt;- make_raster_matrix(data = grid_final)\n\nh &lt;- 762\nw &lt;- 916\n\ntexture &lt;- grDevices::colorRampPalette(cols, bias = 3)(21)                      \n\n\npop_mat %&gt;% \n  rayshader::height_shade(texture = texture) %&gt;% \n  rayshader::plot_3d(\n    heightmap = pop_mat,\n    solid = F,\n    soliddepth = 0,\n    z = 20,\n    shadowdepth = 0,\n    shadow_darkness = .75,\n    windowsize = c(w, h),\n    phi = 65,\n    zoom = .6,\n    theta = -30,\n    background = \"white\"\n  )\n\n# rayshader::render_camera(phi = 35, zoom = .6, theta = -20)\n# \n# rayshader::render_highquality(\n#   filename = \"germany_population_3d.png\",\n#   samples = 500,\n#   preview = T,\n#   light = T,\n#   lightdirection = 0,\n#   lightcolor = \"white\",\n#   lightintensity = 1000,\n#   interactive = F,\n#   width = w, height = h\n# )\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/RugbyResults/6NationResultsWebApp.html",
    "href": "data_visualisations/RugbyResults/6NationResultsWebApp.html",
    "title": "Rugby Results Web App",
    "section": "",
    "text": "This was my first attempt at building a Shiny App based on my previous project. It is more flexible with some interactive text when you hover over the tiles.\nOpen Rugby Results App\n\n\n\nFigure 1\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week05.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week05.html",
    "title": "Simpsons Data Analysis",
    "section": "",
    "text": "Thumbnail\n\n1. R code\n\nShow code# Load the packages in ----------------------------------------------------\n\nif(!require(httr)){install.packages(\"httr\"); library(httr)}\nif(!require(jsonlite)){install.packages(\"jsonlite\"); library(jsonlite)}\nif(!require(withr)){install.packages(\"withr\"); library(withr)}\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(readxl)){install.packages(\"readxl\"); library(readxl)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(gridExtra)){install.packages(\"gridExtra\"); library(gridExtra)}\nif(!require(grid)){install.packages(\"grid\"); library(grid)}\nif(!require(cowplot)){install.packages(\"cowplot\"); library(cowplot)}\nif(!require(showtext)){install.packages(\"showtext\"); library(showtext)}\nif(!require(ggpmisc)){install.packages(\"ggpmisc\"); library(ggpmisc)}\nif(!require(ggimage)){install.packages(\"ggimage\"); library(ggimage)}\nif(!require(jpeg)){install.packages(\"jpeg\"); library(jpeg)}\nif(!require(tinytex)){install.packages(\"tinytex\"); library(tinytex)}\n\n# get the wd\nwd &lt;- getwd()\n\n\n# I have gone beyond the remit of the TidyTuesday and used the whole dataset --------\n# No one cares about the later seasons\n\n# Source for using full dataset: https://github.com/toddwschneider/flim-springfield\n# Define the metadata URL and fetch it\nmetadata_url &lt;- \"www.kaggle.com/datasets/prashant111/the-simpsons-dataset/croissant/download\"\nresponse &lt;- httr::GET(metadata_url)\n\n# Ensure the request succeeded\nif (httr::http_status(response)$category != \"Success\") {\n  stop(\"Failed to fetch metadata.\")\n}\n\n# Parse the metadata\nmetadata &lt;- httr::content(response, as = \"parsed\", type = \"application/json\")\n\n# Locate the ZIP file URL\ndistribution &lt;- metadata$distribution\nzip_url &lt;- NULL\n\nfor (file in distribution) {\n  if (file$encodingFormat == \"application/zip\") {\n    zip_url &lt;- file$contentUrl\n    break\n  }\n}\n\nif (is.null(zip_url)) {\n  stop(\"No ZIP file URL found in the metadata.\")\n}\n\n# Download the ZIP file. We'll use the withr package to make sure the downloaded\n# files get cleaned up when we're done.\ntemp_file &lt;- withr::local_tempfile(fileext = \".zip\")\nutils::download.file(zip_url, temp_file, mode = \"wb\")\n\n# Unzip and read the CSV\nunzip_dir &lt;- withr::local_tempdir()\nutils::unzip(temp_file, exdir = unzip_dir)\n\n# Locate the CSV file within the extracted contents\ncsv_file &lt;- list.files(unzip_dir, pattern = \"\\\\.csv$\", full.names = TRUE)\n\nif (length(csv_file) == 0) {\n  stop(\"No CSV file found in the unzipped contents.\")\n}\n\n# Read the CSV into a dataframe\ncharacters &lt;- read_csv(csv_file[1])\nepisodes &lt;- read_csv(csv_file[2])\nlocations &lt;- read_csv(csv_file[3])\nscript_lines &lt;- read_csv(csv_file[4])\n\n\n\n\n# Load the font and define the theme --------------------------------------\n\n#| warning: false\n#| echo: FALSE\n#| message: false\n\nfont_add_google(\"Permanent Marker\")\nshowtext_auto()\n\n\n# Custom Theme - to emulate the simpson colour scheme of yellow and blue\ncustom_theme &lt;- function() {\n  ggplot2::theme(\n    plot.title.position   = \"plot\",\n    plot.caption.position = \"plot\",\n    plot.title = element_text(size = 60, face = \"bold\", family = \"Permanent Marker\", color = \"#FFD90F\", hjust =  0.5),    \n    plot.subtitle = element_text(size = 48, face = \"bold\", family = \"Permanent Marker\", color = \"#FFD90F\"),    \n    plot.caption = element_text(size = 13,  family = \"Permanent Marker\", color = \"#FFD90F\"),    \n    axis.text = element_text(family = \"Permanent Marker\", size = 13, color = \"#FFD90F\"),   \n    axis.title.x = element_text(size = 32,  family = \"Permanent Marker\", color = \"#FFD90F\"), \n    axis.title.y = element_text(size = 32,  family = \"Permanent Marker\", color = \"#FFD90F\"), \n    axis.line = element_line(linewidth  = 0.5, colour = \"darkgrey\"),\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 20,  family = \"Permanent Marker\", color = \"#FFD90F\"),\n    axis.text.y = element_text(angle = 45, hjust = 1, size = 20, family = \"Permanent Marker\", color = \"#FFD90F\"),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(), \n    panel.background = element_rect(fill = alpha(\"#009DDC\", 0.3),  \n                                    color = \"#009DDC\", \n                                    linewidth = 0.5, \n                                    linetype = \"solid\"),\n    plot.background = element_rect(fill = alpha(\"#009DDC\", 1),  \n                                   color = \"#009DDC\", \n                                   linewidth = 0.5, \n                                   linetype = \"solid\"),\n    legend.background = element_rect(fill = alpha(\"#009DDC\", 0.5),  \n                                     color = \"#009DDC\", \n                                     linewidth = 0.5, \n                                     linetype = \"solid\"),\n    legend.title = element_text(family = \"Permanent Marker\", size = 32, color = \"#FFD90F\"),\n    legend.text = element_text(family = \"Permanent Marker\", size = 32, color = \"#FFD90F\"),\n    legend.position = \"bottom\")\n}\n\n\n# Character Gender Split in the Simpsons --------------------------------------------\n\ngender &lt;- characters %&gt;% \n  select(gender) %&gt;% \n  filter(!is.na(gender)) %&gt;% \n  mutate(gender = str_to_upper(factor(gender)),\n         gender = case_when(gender == \"F\" ~ \"Female\", \n                            gender == \"M\" ~ \"Male\",\n                            TRUE ~ NA))\n\nbarchart_gender &lt;- gender %&gt;% \n  ggplot(aes(x = gender)) +\n  geom_bar(aes(fill = gender))  +\n  geom_text(stat = \"count\", aes(label = after_stat(paste0(\"n = \", count))), \n            vjust = 2, size = 15,  \n            family = \"Permanent Marker\", \n            color = \"#FFD90F\") +\n  scale_fill_brewer(palette = \"Set2\") +  # Use a nice color scheme\n  custom_theme() + \n  labs(subtitle = \"Character Gender Split\", y = \"Number\", fill = \"Gender\")\n\n\n# Heatmap of IMDB Ratings -------------------------------------------------\n\nheat &lt;- episodes %&gt;% \n  select(season, number_in_season, imdb_rating, title) %&gt;%  \n  mutate(season = factor(season),\n         number_in_season = factor(number_in_season))\n# Build a table\n\nmax_rating &lt;- max(heat$imdb_rating, na.rm = TRUE)\nmin_rating &lt;- min(heat$imdb_rating, na.rm = TRUE)\n\n\nlow_rating &lt;- heat %&gt;%\n  filter(imdb_rating == min_rating)\nhigh_rating &lt;- heat %&gt;%\n  filter(imdb_rating == max_rating)\n\nhighlight_episodes &lt;- heat %&gt;%\n  filter(imdb_rating == max_rating | imdb_rating == min_rating) %&gt;%\n  arrange(desc(imdb_rating)) \n\nhighlight_table &lt;- data.frame(\n  `Episode Name` = highlight_episodes$title,\n  `Season` = highlight_episodes$season,\n  `IMDB Rating` = round(highlight_episodes$imdb_rating, 1),\n  check.names=FALSE\n)\n\n#Only way I could work out how to do this to add a title to the table above\n\ntitle_table &lt;- data.frame(matrix(ncol = 1, nrow = 1))\n\ncolnames(title_table) = \"Highest and Lowest Rated Episodes\"\n\ntitle_table[is.na(title_table)] &lt;- \"\"\n\nheatmap_episode &lt;- ggplot(heat, aes(x = season, y = number_in_season, fill = imdb_rating)) +\n  geom_tile() +\n  geom_text(aes(label = round(imdb_rating, 1)),  \n            color = alpha(\"Black\", 0.5),  \n            size = 8,  \n            family = \"Permanent Marker\") +\n  scale_fill_gradient(low = \"firebrick2\", high = \"yellow\", limits = c(4,10)) +  \n  labs(\n    subtitle = \"Heatmap of Episode IMDB Ratings\", \n    x = \"Season Number\",  \n    y = \"Episode Number\", \n    fill = \"IMDB Rating\",\n    caption = \"Grey indicated data not available\") +\n  custom_theme() + \n  theme(legend.position = \"right\") +\n  geom_tile(data = low_rating, \n            aes(x = season, y = number_in_season), \n            color = \"darkred\",\n            linewidth = 1, \n            fill = NA)  + \n  geom_tile(data = high_rating, \n            aes(x = season, y = number_in_season), \n            color = \"darkgreen\",\n            linewidth = 1, \n            fill = NA) +\n  # Add a Table to the graph\n  annotate(geom = \"table\", x = 20, y = 30, label = list(highlight_table), \n           vjust = 1, hjust = 0, family = \"Permanent Marker\", color = alpha(\"black\", 0.5),\n           table.theme = ttheme_minimal(title = \"Highest and Lowest Rated Episodes\",\n                                        base_colour = \"#FFD90F\", base_family = \"Permanent Marker\", color = \"#009DDC\",base_size = 20,\n                                        core=list(bg_params = list(fill = \"#009DDC\")), \n                                        colhead = list(bg_params = list(fill = \"#009DDC\")))) + \n  # Add a table title to the graph (Messy but)\n  annotate(geom = \"table\", x = 20.5, y = 33, label = list(title_table), \n           vjust = 1, hjust = 0, family = \"Permanent Marker\", color = alpha(\"black\", 0.5),\n           table.theme = ttheme_minimal(title = \"Highest and Lowest Rated Episodes\",\n                                        base_colour = \"#FFD90F\", base_family = \"Permanent Marker\", base_size = 20, color = \"#009DDC\",\n                                        core=list(bg_params = list(fill = \"#009DDC\")), \n                                        colhead = list(bg_params = list(fill = \"#009DDC\"))))\n\n\n\n\n# Boxplot of viewership over time -----------------------------------------\n\n\nviewers &lt;- episodes %&gt;% \n  select(season, us_viewers_in_millions) %&gt;% \n  group_by(season) %&gt;% \n  summarise(mean = mean(us_viewers_in_millions),\n            sd =  sd(us_viewers_in_millions),\n            n = n(),\n            se = sd/sqrt(n), \n            lci = mean - qt(1 - (0.05 / 2), n - 1) * se, \n            uci = mean + qt(1 - (0.05 / 2), n - 1) * se)\n\nboxplot_viewers &lt;- ggplot(episodes, aes(x = factor(season), y = us_viewers_in_millions)) +\n  geom_boxplot(fill = alpha(\"firebrick2\", 0.9), color = \"black\", outlier.shape = NA) +  \n  geom_smooth(method = \"lm\", se=FALSE, color= \"#F2E86D\", aes(group=1)) +\n  labs(\n    subtitle = \"US Viewership per Season\",\n    x = \"Season Number\",\n    y = \"US Viewers (Millions)\",\n    caption = \"Yellow Line: Trendline derived from Linear Model\"\n  ) +\n  custom_theme() +\n  theme(plot.caption = element_text(hjust = 0))\n\nwd &lt;- getwd()\n\n\nfig_dir &lt;- paste0(wd, \"/1. Data/1. Images/\")\n\nlines &lt;-script_lines %&gt;% \n  filter(speaking_line == T) %&gt;% \n  rename(Character = raw_character_text) %&gt;% \n  select(Character, word_count) %&gt;% \n  group_by(Character) %&gt;%\n  summarise(n = n())  %&gt;% \n  arrange(desc(n)) %&gt;%  \n  slice(1:10)  %&gt;% \n  mutate(image = case_when(\n    Character ==  \"Homer Simpson\" ~ paste0(fig_dir, \"Homer.png\"),\n    Character ==  \"Marge Simpson\" ~ paste0(fig_dir, \"Marge_Simpson.png\"),\n    Character ==  \"Bart Simpson\" ~ paste0(fig_dir, \"Bart_Simpson_200px.png\"),\n    Character ==  \"Lisa Simpson\" ~ paste0(fig_dir, \"Lisa_Simpson.png\"),\n    Character ==  \"C. Montgomery Burns\" ~ paste0(fig_dir, \"Mr_Burns.png\"),\n    Character ==  \"Moe Szyslak\" ~ paste0(fig_dir, \"Moe_Szyslak.png\"),\n    Character ==  \"Seymour Skinner\" ~ paste0(fig_dir, \"Seymour_Skinner.png\"),\n    Character ==  \"Ned Flanders\" ~ paste0(fig_dir, \"Ned_Flanders.png\"),\n    Character ==  \"Grampa Simpson\" ~ paste0(fig_dir, \"Abe_Simpson.png\"),\n    Character ==  \"Chief Wiggum\" ~ paste0(fig_dir, \"Chief_Wiggum.png\")))\n\n\nbarchart_lines &lt;- lines %&gt;% \n  ggplot(aes(x = reorder(Character, n), y = n, fill = Character)) +  \n  geom_bar(stat = \"identity\") +  \n  geom_image(aes(x = Character, y = -max(n) * 0.05, image = image), \n             size = 0.04, asp = 1) +  \n  geom_text(aes(label = paste0(\"n = \", n), y=n/1.5),  # looks the best\n            hjust= -0.5,\n            position = position_dodge(width = .25),\n            size = 10,  \n            family = \"Permanent Marker\", \n            color = \"#FFD90F\") +\n  coord_flip() + \n  labs(x = \"\", y = \"Number of Lines\", subtitle = \"Most Spoken Lines per Character\") +  \n  custom_theme() +\n  theme(\n    axis.text.y = element_blank(),  \n    axis.ticks.y = element_blank(), \n    legend.position = \"none\"\n  )\n\n\n\n# Combine all the charts and save them in an outputs folder ---------------\n\n\n\n\n\ncombined &lt;- (barchart_gender + boxplot_viewers + barchart_lines) / heatmap_episode +\n  plot_annotation(title = 'The Simpsons',\n                  caption = \"TidyTuesday: Week 5, 2025\",\n                  theme = custom_theme()) +\n  theme(caption = element_text(hjust =  0.5))\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week06.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week06.html",
    "title": "CDC Archive Data Analysis",
    "section": "",
    "text": "R code\n\nDisplay codeif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(survival)){install.packages(\"survival\"); library(survival)}\nif(!require(survminer)){install.packages(\"survminer\"); library(survminer)}\nif(!require(ggfortify)){install.packages(\"ggfortify\"); library(ggfortify)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(sysfonts)){install.packages(\"sysfonts\"); library(sysfonts)}\nif(!require(showtext)){install.packages(\"showtext\"); library(showtext)}\nif(!require(RColorBrewer)){install.packages(\"RColorBrewer\");library(RColorBrewer)}\n\nfont_add_google(\"Roboto Mono\", \"roboto_mono\")\nfont &lt;- \"roboto_mono\"\nshowtext_auto()\n\n# Color palette\ncolor &lt;- palette.colors(palette = \"Okabe-Ito\")\ncolor &lt;- append(color, \"#40B0A6\")\ncolor[1] &lt;- \"#D41159\"\n\n\nCustom_Style &lt;- function() {\n  ggplot2::theme(\n    plot.title = ggplot2::element_text(family=font,\n                                       size=28,\n                                       face=\"bold\",\n                                       color=\"#222222\"),\n    plot.subtitle = ggplot2::element_text(family=font,\n                                          size=20,\n                                          color=\"#222222\"),\n    plot.caption = ggplot2::element_text(family=font,\n                                         size=12,\n                                         color=\"#222222\"),\n    \n    legend.position = \"bottom\",\n    legend.title = ggplot2::element_text(family=font, \n                                         size=12, \n                                         face=\"bold\", \n                                         color=\"#222222\"),\n    # legend.text.align = 0,\n    legend.key = ggplot2::element_blank(),\n    legend.text = ggplot2::element_text(family=font,\n                                        size=9,\n                                        color=\"#222222\"),\n    \n    # Axis format\n    axis.text = ggplot2::element_text(family = font,\n                                      size=10,\n                                      color=\"#222222\"),\n    axis.text.x = ggplot2::element_text(margin=ggplot2::margin(5, b = 10)),\n    axis.line = ggplot2::element_line(colour = alpha('#222222', 0.5), size =0.5),\n    axis.title = ggplot2::element_text(family=font, \n                                         size=12, \n                                         face=\"bold\", \n                                         color=\"#222222\"),\n    \n    \n    # Grid lines\n    panel.grid.minor = ggplot2::element_blank(),\n    panel.grid.major.y = ggplot2::element_blank(),\n    panel.grid.major.x = ggplot2::element_blank(),\n    \n    \n    \n    # Very pale cream/yellow background\n    panel.background = element_rect(fill = \"#FFFBF0\",  \n                                    color = \"#FFFBF0\", \n                                    linewidth = 0.5, \n                                    linetype = \"solid\"),\n    plot.background = element_rect(fill = \"#FFFBF0\",  \n                                   color = \"#FFFBF0\", \n                                   linewidth = 0.5, \n                                   linetype = \"solid\"),\n    legend.background = element_rect(fill = \"#FFFBF0\",  \n                                     color = \"#FFFBF0\", \n                                     linewidth = 0.5, \n                                     linetype = \"solid\"),\n    \n    \n  )\n}\n\n\n\n\ncdc_datasets &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/cdc_datasets.csv')\nfpi_codes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/fpi_codes.csv')\nomb_codes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-11/omb_codes.csv')\n\n\n\nAgency &lt;- omb_codes %&gt;% \n  group_by(agency_name) %&gt;% \n  summarise(n = n()) %&gt;% \n  arrange(desc(n)) %&gt;% \n  slice(1: 10)\n\np1 &lt;- Agency %&gt;% \n  ggplot(aes(x = fct_reorder(agency_name, n, .desc = TRUE), y = n)) +   # Explicitly set y to n\n  geom_col(aes(fill = as.factor(agency_name))) +   # Use geom_col() instead of geom_bar()\n  labs(subtitle = str_wrap(\"CDC Database Archiving: Top 10 Agencies  that have archived databases since 2016\", 40), x = \"Agency Name\", y = \"Count (n)\", fill = \"Agency Name\") + \n  geom_text(aes(label = paste0(\"n = \", n)), \n            vjust = -0.5,   # Position above the bar\n            size = 4,       # Adjusted size for better readability\n            family = font) +\n  Custom_Style() +\n  scale_fill_manual(values = color) +\n  scale_x_discrete(labels = function(x) str_wrap(x, width =10)) +\n  theme(legend.position = \"none\",\n    legend.title = element_blank(),\n        axis.text.x = element_text(size = 6))\n\ntimeline_data &lt;- cdc_datasets %&gt;% \n  mutate(\n    level_of_access = case_when(\n      public_access_level %in% c(\"public\", \"public domain\") ~ \"Public Access\",\n      public_access_level == \"restricted public\" ~ \"Restricted Access\",\n      public_access_level == \"non-public\" ~ \"No Public Access\",\n      TRUE ~ \"Unspecified\"\n    ),\n    issued = as.Date(issued)\n  )  %&gt;% \n  filter(!is.na(issued)) |&gt;\n  arrange(issued) %&gt;% \n  mutate(\n    Time_to_Archiv = as.numeric(issued - min(issued)),\n    Evt = 1,\n    archival_date = min(issued) + Time_to_Archiv\n  )\n\n\nmin &lt;- min(timeline_data$issued)\n\nkm_fit &lt;- survfit(Surv(Time_to_Archiv, Evt) ~ 1, data = timeline_data)\n\nkm_df &lt;- data.frame(\n  time = km_fit$time,\n  survival = km_fit$surv,\n  cumulative_events = 1 - km_fit$surv,\n  archival_date = min(timeline_data$issued) + km_fit$time\n)\n\np2 &lt;- ggplot(km_df, aes(x = archival_date, y = cumulative_events)) +\n  geom_step(color = \"#40B0A6\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +  # Format x-axis as years\n  labs(x = \"Year\", y = \"Archival Events\", subtitle = str_wrap(\"Kaplan-Meier Curve of Archiving of CDC Databases\", 40), caption = \"Each step signifies an increase in database archiving \\n TidyTuesday: Week 6, 2025\") +\n  Custom_Style() +\n  theme(axis.text.y = element_blank())\n\np1\n\n\n\n\n\n\nDisplay codep2\n\n\n\n\n\n\nDisplay codep_combined &lt;- p1 + p2 \n\n\np_combined +\n  Custom_Style() +\n  plot_annotation(title = \"CDC Database Archiving Analysis\",\n                  theme = Custom_Style()) +\n  theme(caption = element_text(hjust =  0.5))\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week12.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week12.html",
    "title": "TidyTuesday Week 12: Amazon‚Äôs Annual Reports",
    "section": "",
    "text": "Thumbnail\n\n1. R code\n\nShow code# Load the packages in ----------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(ggplot2)){install.packages(\"ggplot2\"); library(ggplot2)}\nif(!require(ggwordcloud)){install.packages(\"ggwordcloud\"); library(ggwordcloud)}\n# I stick all my styling into a CUsotm PAckage to tidy up my code and keep it consistent over the time\nif(!require(CustomGGPlot2Theme)){devtools::install(\"CustomGGPlot2Theme\"); library(CustomGGPlot2Theme)}\n\n# get the wd\nwd &lt;- getwd()\n\nfont &lt;- \"noto_mono\"\namazon &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-25/report_words_clean.csv')\n\n\ndata_clean &lt;- amazon %&gt;%\n  filter(year &gt;= 2013) %&gt;%\n  group_by(year, word) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%     \n  arrange(year, desc(count)) %&gt;% # Sort within each year by count\n  group_by(year) %&gt;%\n  slice(1:15) %&gt;% # Select top 15 words per year\n  ungroup() %&gt;%\n  filter(word != \"aaa\") %&gt;% \n  mutate(word = str_remove_all(word, \"&lt;.*?&gt;\"))\n\n\n\n\nwordcloud  &lt;- ggplot(data_clean, aes(label = word, size = count, color = count)) +\n  geom_text_wordcloud(area_corr = TRUE) +\n  facet_wrap(~ year) +\n  scale_size_area(max_size = 15) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  Custom_Style() +\n  theme(\n    strip.background = element_rect(fill = \"#FFFBF0\", color = \"#FFFBF0\"), \n    strip.text = element_text(size = 32, face = \"bold\", color = \"black\", family = font, hjust = 0) )\n\np1 &lt;- wordcloud +\n  plot_annotation(\n    title = str_wrap(\"Word Cloud of Top 15 Most Commonly used words in Amazon's Annual Report (2013-2023)\", 40),\n    subtitle = \"TidyTuesday: Week 12, 2025\",\n    theme = Custom_Style()\n  ) &\n  theme(\n    caption = element_text(hjust = 0.5),\n    plot.subtitle = element_text(size = 20),\n    plot.title = element_text(size = 32)\n  )\n\nggsave(\n  filename = \"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/thumbnails/TidyTues_Week12.png\", \n  plot = p1, \n  height = 1080 / 96,  # Converts 1240px to inches (assuming 96 DPI)\n  width = 1080 / 96,    # Converts 1080px to inches\n  dpi = 96,             # Set DPI to 96 to match pixel dimensions\n  units = \"in\",\n)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week20.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week20.html",
    "title": "TidyTuesday Week 20: Water Quality at Sydney Beaches",
    "section": "",
    "text": "Water Quality :::\n1. R code\n\nShow code# Load the packages in ----------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(ggplot2)){install.packages(\"ggplot2\"); library(ggplot2)}\nif(!require(scales)){install.packages(\"scales\"); library(scales)}\nif(!require(RColorBrewer)){install.packages(\"RColorBrewer\"); library(RColorBrewer)}\n# I stick all my styling into a CUsotm PAckage to tidy up my code and keep it consistent over the time\nif(!require(CustomGGPlot2Theme)){devtools::install(\"CustomGGPlot2Theme\"); library(CustomGGPlot2Theme)}\n\n\n\nwater_quality &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-05-20/water_quality.csv')\nweather &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-05-20/weather.csv') %&gt;% \n  select(-c(longitude, latitude))\nwater_quality$date &lt;- as.Date(water_quality$date)\nweather$date &lt;- as.Date(weather$date)\n\n# Remove specific years\n\ncombined &lt;- left_join(water_quality, weather, by = \"date\") %&gt;% \n  mutate(Year = year(date),\n         Month = month(date, label = T),\n         Day = day(date)) %&gt;% \n  filter(Year &gt;= 2000,\n         Year != 2025)\n\n\n# Average temperature by Year and Month\nstripes_data &lt;- combined %&gt;%\n  group_by(Year, Month) %&gt;%\n  summarise(avg_temp = mean(max_temp_C, na.rm = TRUE),\n            average_bacteria = mean(enterococci_cfu_100ml, na.rm = T), \n            average_rain = mean(precipitation_mm, na.rm = T),.groups = \"drop\")\n\n\n# Fix error in mean calculation\nmaxmin &lt;- range(stripes_data$avg_temp, na.rm = TRUE)\nmd &lt;- mean(stripes_data$avg_temp, na.rm = TRUE)  # Fixed: was incorrectly referring to `stripes_data$stripes_data`\n\n# Color palette\ncol_strip &lt;- brewer.pal(11, \"RdBu\")\ncol_strip &lt;- adjustcolor(col_strip, alpha.f = 0.5)\n\n# Create a date column for plotting (necessary for proper x-axis handling)\n# Ensure Month is a factor for correct month ordering\n\n\nstripes_data$Month_num &lt;- as.numeric(stripes_data$Month)\n# Compute the original ranges for correct inverse transformation\n# Compute the original ranges for correct inverse transformation\n# Compute the original ranges for correct inverse transformation\nrain_range &lt;- range(stripes_data$average_rain, na.rm = TRUE)\nbac_range  &lt;- range(stripes_data$average_bacteria, na.rm = TRUE)\n\np1 &lt;- ggplot(stripes_data, aes(x = Month, y = 1, fill = avg_temp)) +\n  geom_tile(height = 0.4) +  # Explicit tile height kept for visibility\n  \n  scale_fill_gradientn(\n    colors = rev(col_strip),\n    values = rescale(c(maxmin[1], md, maxmin[2])),\n    na.value = \"gray80\"\n  ) +\n  \n  # Overlay bacteria as points ‚Äì now with a mapping that creates a legend entry:\n  geom_point(\n    aes(\n      x = Month_num, \n      y = scales::rescale(average_bacteria, to = c(0.8, 1.2)),\n      color = \"Average Enterococci per 100ml\"  # This will create a legend key labeled \"Bacteria\"\n    ),\n    size = 0.5,\n    group = 1\n  ) +\n  geom_segment(aes(x = Month_num, xend = Month_num, y = 0.8, yend = scales::rescale(average_bacteria, to = c(0.8, 1.2))),\n               color = \"black\", size = 0.5) +\n  \n  # Overlay rainfall as a line ‚Äì now with a mapping that creates a legend entry:\n  geom_line(\n    aes(\n      x = Month_num, \n      y = scales::rescale(average_rain, to = c(0.8, 1.2)),\n      color = \"Average Monthly Rainfall (mm)\"  # This will create a legend key labeled \"Rainfall\"\n    ),\n    size = 0.5,\n    group = 1\n  ) +\n  \n  labs(\n    title = str_wrap(\"Relationship between Average Enterococci per 100ml, Average Temperature, and Average Rainfall\", 70),\n    caption = \"Tidy Tuesday 2025 Week 20\",\n    x = \"Month\",\n    y = NULL,\n    fill = \"Avg Temp (¬∞C)\"\n  ) +\n  \n  Custom_Style() +  # Use your pre-defined theme_strip, if available\n  theme(\n    panel.grid = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    # Make facet label strips transparent:\n    strip.background = element_rect(fill = \"transparent\", color = NA)\n  ) +\n  \n  # Dual y-axis: left for rainfall, right for bacteria\n  scale_y_continuous(\n    name = \"Average Monthly Rainfall (mm)\",\n    limits = c(0.8, 1.2),\n    breaks = seq(0.8, 1.2, length.out = 5),\n    labels = function(x) {\n      # Inverse transformation for rainfall:\n      round((x - 0.8) / 0.4 * diff(rain_range) + rain_range[1], digits = 1)\n    },\n    sec.axis = sec_axis(\n      trans = ~ (. - 0.8) / 0.4 * diff(bac_range) + bac_range[1],\n      name = \"Average Enterococci per 100ml\"\n    )\n  ) +\n  scale_color_manual(\n    name = \"\",\n    values = c(\"Average Enterococci per 100ml\" = \"black\", \"Average Monthly Rainfall (mm)\" = \"blue\"),\n    guide = guide_legend(\n      override.aes = list(\n        linetype = c(0, 1),  \n        shape = c(16, NA)     \n      )\n    )\n  ) +\n  \n  facet_wrap(~ Year)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week14.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week14.html",
    "title": "TidyTuesday Week 14: Timely and Effective Care by US State",
    "section": "",
    "text": "#### 1. Python code\n\n\nShow code\nimport pandas as pd\nimport os\nimport geopandas as gpd\nfrom plotnine import (\n    ggplot,\n    aes,\n    coord_fixed,\n    facet_wrap,\n    geom_map,\n    geom_polygon,\n    geom_text,\n    labs,\n    scale_fill_brewer,\n    scale_fill_continuous,\n    scale_x_continuous,\n    scale_y_continuous,\n    scale_size_continuous,\n    stage,\n    coord_cartesian,\n    element_line,\n    element_rect,\n    element_text,\n    theme_void,\n    theme,\n)\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom plotnine import scale_fill_gradient\n\n\npcare_state = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-08/care_state.csv')\n\n\n\n# Filter the data for Emergency Department and relevant states\nexcluded_states = [\"DC\", \"GU\", \"MH\", \"MP\", \"PR\", \"VI\", \"AS\", \"AL\", \"HI\"]\ned_data = pcare_state[\n    (pcare_state[\"condition\"] == \"Emergency Department\") &\n    (~pcare_state[\"state\"].isin(excluded_states)) &\n    (pcare_state[\"measure_id\"] == \"OP_22\")\n]\n\n# Load state boundary shapefile\nstate_data = gpd.read_file(\"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/maps/ne_110m_admin_1_states_provinces.shp\")\nexcluded_states = [\"HI\", \"AK\"]  # Exclude Hawaii and Alaska\nstate_data = state_data[~state_data['postal'].isin(excluded_states)]\nstate_data = state_data[state_data['admin'] == 'United States of America']\n\n# Merge state boundaries with Emergency Department data\nstate_data['postal'] = state_data['postal'].str.upper()\nmerged_data = state_data.merge(ed_data, left_on=\"postal\", right_on=\"state\", how=\"left\")\n\n# Calculate the centroid of each state for text placement\nmerged_data['centroid'] = merged_data.geometry.centroid\nmerged_data['centroid_x'] = merged_data['centroid'].apply(lambda x: x.x)\nmerged_data['centroid_y'] = merged_data['centroid'].apply(lambda x: x.y)\n\n# Explode multi-part geometries into individual rows\nmerged_data = merged_data.explode(index_parts=False)\n\n# Extract polygon coordinates\ndef get_coords(row):\n    if isinstance(row.geometry, Polygon):\n        exterior = row.geometry.exterior.coords\n        return list(exterior)\n    elif isinstance(row.geometry, MultiPolygon):\n        # Take only the largest polygon (simplification)\n        largest_poly = max(row.geometry.geoms, key=lambda a: a.area)\n        return list(largest_poly.exterior.coords)\n    else:\n        return None\n\nmerged_data[\"coords\"] = merged_data.apply(get_coords, axis=1)\nmerged_data = merged_data.explode(\"coords\", ignore_index=True)\n\n# Create longitude and latitude columns\nmerged_data[\"longitude\"] = merged_data[\"coords\"].apply(lambda x: x[0])\nmerged_data[\"latitude\"] = merged_data[\"coords\"].apply(lambda x: x[1])\n\nmerged_data[\"score_label\"] = merged_data[\"score\"].apply(\n    lambda x: f\"{round(x)}%\" if pd.notnull(x) else \"\"\n)\n\n\n\n# Now plot\n\nplot = (\n    ggplot(merged_data)\n    + geom_polygon(\n        aes(x=\"longitude\", y=\"latitude\", group=\"postal\", fill=\"score\"),\n        color=\"black\"\n    )\n    + geom_text(\n        aes(x=\"centroid_x\", y=\"centroid_y\", label=\"score_label\"),\n        size=7,\n        color=\"black\"\n    )\n    + scale_fill_gradient(name=\"Percent\", low=\"#f1eef6\", high=\"#045a8d\")\n    + labs(\n        title=\"Percentage of Patients Who Left the\\nEmergency Department Before Being Seen\"\n    )\n    + coord_fixed()\n    + theme_void()\n    + theme(\n        legend_position=\"bottom\",\n        legend_title=element_text(size=10, weight=\"bold\"),\n        legend_text=element_text(size=8),\n        plot_title=element_text(size=14, weight=\"bold\")\n    )\n)\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week07.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week07.html",
    "title": "CDC Archive Data Analysis",
    "section": "",
    "text": "Thumbnail\n\nR code\n\nDisplay code# Set Up ------------------------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(survival)){install.packages(\"survival\"); library(survival)}\nif(!require(survminer)){install.packages(\"survminer\"); library(survminer)}\nif(!require(ggfortify)){install.packages(\"ggfortify\"); library(ggfortify)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(sysfonts)){install.packages(\"sysfonts\"); library(sysfonts)}\nif(!require(showtext)){install.packages(\"showtext\"); library(showtext)}\nif(!require(RColorBrewer)){install.packages(\"RColorBrewer\"); library(RColorBrewer)}\nif(!require(maps)){install.packages(\"maps\"); library(maps)}\nif(!require(sf)){install.packages(\"sf\"); library(sf)}\nif(!require(rlist)){install.packages(\"rlist\"); library(rlist)}\n\nwd &lt;- getwd()\n\n\n\n# Graph Style -------------------------------------------------------------\n\n\n\nfont_add_google(\"Roboto Mono\", \"roboto_mono\")\nfont &lt;- \"roboto_mono\"\nshowtext_auto()\n\n# Color palette\ncolor &lt;- palette.colors(palette = \"Okabe-Ito\")\ncolor &lt;- append(color, \"#40B0A6\")\ncolor[1] &lt;- \"#D41159\"\n\n\nCustom_Style &lt;- function() {\n  ggplot2::theme(\n    plot.title = ggplot2::element_text(family=font,\n                                       size=28,\n                                       face=\"bold\",\n                                       color=\"#222222\"),\n    plot.subtitle = ggplot2::element_text(family=font,\n                                          size=20,\n                                          color=\"#222222\"),\n    plot.caption = ggplot2::element_text(family=font,\n                                         size=12,\n                                         color=\"#222222\"),\n    \n    legend.position = \"bottom\",\n    legend.title = ggplot2::element_text(family=font, \n                                         size=12, \n                                         face=\"bold\", \n                                         color=\"#222222\"),\n    # legend.text.align = 0,\n    legend.key = ggplot2::element_blank(),\n    legend.text = ggplot2::element_text(family=font,\n                                        size=9,\n                                        color=\"#222222\"),\n    \n    # Axis format\n    axis.text = ggplot2::element_text(family = font,\n                                      size=10,\n                                      color=\"#222222\"),\n    axis.text.x = ggplot2::element_text(margin=ggplot2::margin(5, b = 10), size =8),\n    axis.line = ggplot2::element_line(colour = alpha('#222222', 0.5), size =0.5),\n    axis.title = ggplot2::element_text(family=font, \n                                       size=12, \n                                       face=\"bold\", \n                                       color=\"#222222\"),\n    \n    \n    # Grid lines\n    panel.grid.minor = ggplot2::element_blank(),\n    panel.grid.major.y = ggplot2::element_blank(),\n    panel.grid.major.x = ggplot2::element_blank(),\n    \n    \n    \n    # Very pale cream/yellow background\n    panel.background = element_rect(fill = \"#FFFBF0\",  \n                                    color = \"#FFFBF0\", \n                                    linewidth = 0.5, \n                                    linetype = \"solid\"),\n    plot.background = element_rect(fill = \"#FFFBF0\",  \n                                   color = \"#FFFBF0\", \n                                   linewidth = 0.5, \n                                   linetype = \"solid\"),\n    legend.background = element_rect(fill = \"#FFFBF0\",  \n                                     color = \"#FFFBF0\", \n                                     linewidth = 0.5, \n                                     linetype = \"solid\"),\n    \n    \n  )\n}\n\n\n# Load the Data -----------------------------------------------------------\n\n\nagencies &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-18/agencies.csv') %&gt;% \n  mutate(is_nibrs = case_when(\n    is_nibrs == TRUE ~ \"Yes\",\n    is_nibrs == FALSE ~ \"No\",\n    TRUE ~ NA\n  ))\n\n\n# Simple Agency Graph -----------------------------------------------------\n\nstates &lt;- c(\"New York\", \"Texas\", \"Massachusetts\", \"California\", \"Oklahoma\", \"Illinois\")\n\nAgencyType &lt;-agencies %&gt;% \n  filter(state %in% states) %&gt;% \n  group_by(state, agency_type) %&gt;% \n  summarise(n= n())\n\np1 &lt;- AgencyType %&gt;% \n  group_by(state) %&gt;%  # Ensure percentage is calculated within each state\n  mutate(percent = n / sum(n)) %&gt;%  # Compute percent per state\n  ggplot(aes(x = state, y = percent, fill = agency_type)) + \n  geom_bar(stat = \"identity\", position = \"fill\") +  \n  geom_text(aes(label = scales::percent(percent, accuracy = 1)),  \n            position = position_stack(vjust = 0.5),  \n            size = 3,  \n            family = font,  \n            color = \"black\") +  \n  labs(subtitle = str_wrap(\"The percentage of agencies reporting into the NIBRS by state\", 60), x = \"State\", y = \"Percent\", fill =\"State\") +  \n  Custom_Style() +  \n  scale_y_continuous(labels = scales::percent_format()) +  \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  \n\n\n\n# Mapping PD reporting by Masseucsuttes, California New York versus Texas --------------------------------------------------------\n\npolice_data &lt;- agencies %&gt;% \n  select(longitude, latitude, state, is_nibrs, agency_type) %&gt;% \n  filter(!is.na(longitude) & !is.na(latitude))  \n\nsf_data &lt;- st_as_sf(police_data, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nloop &lt;- map_data(\"state\") %&gt;% \n  filter(region %in% c(\"new york\", \"texas\", \"massachusetts\", \"california\", \"oklahoma\", \"illinois\")) %&gt;% \n  arrange(region)\n\nstate &lt;- unique(loop$region)\n\npolice_state &lt;- sf_data %&gt;% \n  mutate(state = tolower(state)) %&gt;%  # Convert to lowercase\n  filter(state %in% c(\"new york\", \"texas\", \"massachusetts\", \"california\", \"oklahoma\", \"illinois\"))\n\npolicestate &lt;- unique(police_state$state)\n\nlist_of_maps &lt;- list()\ns=2\nfor (s in 1:length(state)) {\n  \n  # Ensure state filtering is correct\n  state_map &lt;- map_data(\"state\") %&gt;% \n    filter(region == state[s])\n  \n  police_filtered &lt;- police_state %&gt;% \n    filter(state == policestate[s])  # Use a fresh filter for each iteration\n  \n  p2 &lt;- ggplot() +\n    geom_polygon(data = state_map, \n                 aes(x = long, y= lat, group = group), fill = color[4]) +\n    geom_sf(data = police_filtered, aes(color = is_nibrs), size = 0.2) +\n    labs(subtitle = str_to_title(state[s]),\n         x = \"Longitude\",\n         y = \"Latitude\",\n         fill = \"Density\",\n         color = \"Reports to NIBRS\") + \n    Custom_Style() +\n    scale_color_manual(values = c(color[1], color[2])) +\n    theme(\n      axis.line = element_blank(),\n      axis.ticks = element_blank(),\n      axis.title = element_blank(),\n      axis.text.x = element_blank(),\n      axis.text.y = element_blank(),\n      panel.grid = element_blank(),\n      plot.title = ggplot2::element_text(family=font,\n                                         size=20,\n                                         face=\"bold\",\n                                         color=\"#222222\")\n    )\n  \n  list_of_maps[[s]] &lt;- p2\n}\n\ncombined &lt;-  wrap_plots(list_of_maps)\n\nggsave(\n  filename = \"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/thumbnails/TidyTues_Week07a.png\", \n  plot = combined, \n  height = 1240 / 96,  # Converts 1240px to inches (assuming 96 DPI)\n  width = 1080 / 96,    # Converts 1080px to inches\n  dpi = 96,             # Set DPI to 96 to match pixel dimensions\n  units = \"in\",\n)\n\n\nggsave(\n  filename = \"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/thumbnails/TidyTues_Week07b.png\", \n  plot = p1, \n  height = 1240 / 96,  # Converts 1240px to inches (assuming 96 DPI)\n  width = 1080 / 96,    # Converts 1080px to inches\n  dpi = 96,             # Set DPI to 96 to match pixel dimensions\n  units = \"in\",\n)\n\n\nggsave(\n  filename = \"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/TidyTues_Week07a.png\", \n  plot = combined, \n  height = 1240 / 96,  # Converts 1240px to inches (assuming 96 DPI)\n  width = 1080 / 96,    # Converts 1080px to inches\n  dpi = 96,             # Set DPI to 96 to match pixel dimensions\n  units = \"in\",\n)\n\n\nggsave(\n  filename = \"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/TidyTues_Week07b.png\", \n  plot = p1, \n  height = 1240 / 96,  # Converts 1240px to inches (assuming 96 DPI)\n  width = 1080 / 96,    # Converts 1080px to inches\n  dpi = 96,             # Set DPI to 96 to match pixel dimensions\n  units = \"in\",\n)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week13.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week13.html",
    "title": "TidyTuesday Week 13: Pokemon",
    "section": "",
    "text": "(a) Thumbnail 1\n\n\n\n\n\n\n\n\n\n(b) Thumbnail 2\n\n\n\n\n\n\nFigure¬†1: Tidy Tuesday Week 13: Charts\n\n\n1. R code\n\nShow code# Load the packages in ----------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(ggplot2)){install.packages(\"ggplot2\"); library(ggplot2)}\nif(!require(ggwordcloud)){install.packages(\"ggwordcloud\"); library(ggwordcloud)}\nif(!require(ggpmisc)){install.packages(\"ggpmisc\"); library(ggpmisc)}\nif(!require(ggimage)){install.packages(\"ggimage\"); library(ggimage)}\nif(!require(ggtext)){install.packages(\"ggtext\"); library(ggimage)}\nif(!require(rlist)){install.packages(\"rlist\"); library(rlist)}\n# I stick all my styling into a CUsotm PAckage to tidy up my code and keep it consistent over the time\nif(!require(CustomGGPlot2Theme)){devtools::install(\"CustomGGPlot2Theme\"); library(CustomGGPlot2Theme)}\n\n# get the wd - force of habit\nwd &lt;- getwd()\n#pulling images off internet was taking a lot of time and casing a time out error\noptions(timeout = 1000) \n\n\n\nfont &lt;- \"noto_mono\"\n\npokemon_df &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-01/pokemon_df.csv')\n\n# I only care about first gen - Older Millenial\n\nfirst_gen &lt;- pokemon_df %&gt;% \n  filter(generation_id == 1) %&gt;% \n  #for later\n  rename(\"special attack\" = special_attack)\n\n# going to loop through attack, defence, special attack, speed\n\ncolumns &lt;- c(\"attack\", \"defense\", \"special attack\", \"speed\")\nn = 3\n\n#empty list of plots\nlist_of_plots &lt;- list()\n\nfor(n in 1: length(columns)) {\n  \n  data &lt;- first_gen %&gt;%\n    group_by(type_1) %&gt;%\n    slice_max(order_by = .data[[columns[n]]], n = 1, with_ties = FALSE) %&gt;%\n    ungroup() %&gt;%\n    arrange(.data[[columns[n]]])  # Correct dynamic column referencing\n  \n  #Make labels with a picture of the Pokemon and then the name of the pokemon underneath\n  # Generate labels after sorting\n  labels &lt;- paste0(\n    \"&lt;img src='\", data$url_image, \"' width='45' height='35' /&gt;&lt;br&gt;\",\n    \"&lt;span style='font-size:16px;'&gt;\", # Add font size styling here\n    sapply(strwrap(str_to_title(data$pokemon), width = 20, simplify = FALSE), \n           function(x) paste(x, collapse = \"&lt;br&gt;\")),\n    \"&lt;/span&gt;\"\n  )\n  \n  \n  \n  chart &lt;- data %&gt;%\n    ggplot(aes(x = reorder(pokemon, .data[[columns[n]]]), \n               y = .data[[columns[n]]], \n               fill = str_to_title(type_1))) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = .data[[columns[n]]]),  \n              hjust = -0.5,\n              position = position_dodge(width = 0.25),\n              size = 6,  \n              family = font) +\n    coord_flip() +\n    labs(x = \"Pok√©mon\", \n         y = paste0(str_to_title(columns[n]), \" Score\"), \n         subtitle = str_to_title(columns[n]),\n         fill = \"Pok√©mon Type\") +  \n    Custom_Style() +\n    theme(axis.text.y = element_markdown(), \n          legend.text = element_text(size = 15),\n          axis.text = element_text(size = 12)) +\n    scale_x_discrete(labels = labels)  \n  \n  list_of_plots &lt;- list.append(list_of_plots, chart)\n  \n}\n\n#single plot to look good for social media\nsingle_chart &lt;- list_of_plots[[1]]\n\nsingle_chart &lt;- single_chart +\n  labs(\n    title = 'Visualisation of various Pok√©mon stats by their Attack',\n    subtitle = \"TidyTuesday: Week 13, 2025\",\n    theme = Custom_Style()\n  ) +\n  theme(\n    plot.subtitle = element_text(size = 16)\n  )\n\n\npatchwork &lt;- wrap_plots(list_of_plots) +\n  plot_layout(guides = \"collect\") +\n  plot_annotation(\n    title = str_wrap('Visualisation of various Pok√©mon stats by their type', 80),\n    subtitle = \"TidyTuesday: Week 13, 2025\",\n    theme = Custom_Style()\n  ) &\n  theme(\n    plot.title = element_text(size = 24),\n    plot.subtitle = element_text(size = 16)\n  )\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/Tidy_Tues_Week31.html",
    "href": "data_visualisations/TidyTuesday/2025/Tidy_Tues_Week31.html",
    "title": "TidyTuesday Week 31: British Library Funding",
    "section": "",
    "text": "::: #### 1. Python code\n\n\nShow code\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nincome_inequality_processed = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-08-05/income_inequality_processed.csv')\nincome_inequality_raw = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-08-05/income_inequality_raw.csv')\n\ncountries = [\"United States\", \"Germany\", \"France\", \"Italy\", \"Spain\", \"UK\"]\n\ndf = income_inequality_processed[income_inequality_processed[\"Entity\"].isin(countries)]\n\n# Only that after 20008\n\ndf = df[df[\"Year\"] &gt;= 2008]\n\nheatmap_data_b4_tax = df.pivot(index=\"Entity\", columns=\"Year\", values=\"gini_mi_eq\")\nheatmap_data_aft_tax = df.pivot(index=\"Entity\", columns=\"Year\", values=\"gini_dhi_eq\")\n\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 8), sharey=True)\n\nsns.heatmap(heatmap_data_b4_tax, \n            cmap=\"YlOrRd\", \n            ax=axes[0])\naxes[0].set_title(\"Before-Tax Income Inequality\")\naxes[0].set_xlabel(\"Year\")\naxes[0].set_ylabel(\"Country\")\n\nsns.heatmap(heatmap_data_aft_tax, \n            cmap=\"YlOrRd\", \n            ax=axes[1])\naxes[1].set_title(\"After-Tax Income Inequality\")\naxes[1].set_xlabel(\"Year\")\naxes[1].set_ylabel(\"\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week09.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week09.html",
    "title": "TidyTuesday Week 9: Long Beach Animal Shelter",
    "section": "",
    "text": "Figure 1\n\n\nDisplay code# gc()\n# \n# rm(list = ls())\n# \n# graphics.off()\n# \n# cat('\\014')\n# \n\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\n\nif(!require(ggbrick)){install.packages(\"ggbrick\"); library(ggbrick)}\n\nif(!require(ggfortify)){install.packages(\"ggfortify\"); library(ggfortify)}\n\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\n\nif(!require(sysfonts)){install.packages(\"sysfonts\"); library(sysfonts)}\n\nif(!require(showtext)){install.packages(\"showtext\"); library(showtext)}\n\nif(!require(RColorBrewer)){install.packages(\"RColorBrewer\"); library(RColorBrewer)}\n\nif(!require(maps)){install.packages(\"maps\"); library(maps)}\n\nif(!require(rcrossref)){install.packages(\"rcrossref\"); library(rcrossref)}\n\nif(!require(ggshadow)){install.packages(\"ggshadow\"); library(ggshadow)}\n\nif(!require(ggridges)){install.packages(\"ggridges\"); library(ggridges)}\n\nif(!require(ggpp)){install.packages(\"ggpp\"); library(ggpp)}\n\nif(!require(gridExtra)){install.packages(\"gridExtra\"); library(gridExtra)}\n\nif(!require(sf)){install.packages(\"sf\"); library(sf)}\n\nif(!require(ggmap)){install.packages(\"ggmap\"); library(ggmap)}\nif(!require(osmdata)){install.packages(\"osmdata\"); library(osmdata)}\n\nwd &lt;- getwd()\n\n\n\n\n\nfont_add_google(\"Noto Sans Mono\", \"noto_mono\")\n\nfont &lt;- \"noto_mono\"\n\nshowtext_auto()\n\n\n\n# Color palette\n\ncolor &lt;- palette.colors(palette = \"Okabe-Ito\")\n\ncolor &lt;- append(color, \"gold\")\n\ncolor[1] &lt;- \"#D41159\"\n\n\n\n\n\nCustom_Style &lt;- function() {\n  \n  ggplot2::theme(\n    \n    plot.title = ggplot2::element_text(family=font,\n                                       \n                                       size=24,\n                                       \n                                       face=\"bold\",\n                                       \n                                       color=\"#222222\"),\n    \n    plot.subtitle = ggplot2::element_text(family=font,\n                                          \n                                          size=18,\n                                          \n                                          color=\"#222222\"),\n    \n    plot.caption = ggplot2::element_text(family=font,\n                                         \n                                         size=10,\n                                         \n                                         color=\"#222222\"),\n    \n    \n    \n    legend.position = \"bottom\",\n    \n    legend.title = ggplot2::element_text(family=font,\n                                         \n                                         size=12,\n                                         \n                                         face=\"bold\",\n                                         \n                                         color=\"#222222\"),\n    \n    # legend.text.align = 0,\n    \n    legend.key = ggplot2::element_blank(),\n    \n    legend.text = ggplot2::element_text(family=font,\n                                        \n                                        size=9,\n                                        \n                                        color=\"#222222\"),\n    \n    \n    \n    # Axis format\n    \n    axis.text = ggplot2::element_text(family = font,\n                                      \n                                      size=10,\n                                      \n                                      color=\"#222222\"),\n    \n    axis.text.x = ggplot2::element_text(margin=ggplot2::margin(5, b = 10), size =8),\n    \n    axis.line = ggplot2::element_line(colour = alpha('#222222', 0.5), size =0.5),\n    \n    axis.title = ggplot2::element_text(family=font,\n                                       \n                                       size=12,\n                                       \n                                       face=\"bold\",\n                                       \n                                       color=\"#222222\"),\n    \n    \n    \n    \n    \n    # Grid lines\n    \n    panel.grid.minor = ggplot2::element_blank(),\n    \n    panel.grid.major.y = ggplot2::element_blank(),\n    \n    panel.grid.major.x = ggplot2::element_blank(),\n    \n    \n    \n    \n    \n    \n    \n    # Very pale cream/yellow background\n    \n    panel.background = element_rect(fill = \"#FFFBF0\", \n                                    \n                                    color = \"#FFFBF0\",\n                                    \n                                    linewidth = 0.5,\n                                    \n                                    linetype = \"solid\"),\n    \n    plot.background = element_rect(fill = \"#FFFBF0\", \n                                   \n                                   color = \"#FFFBF0\",\n                                   \n                                   linewidth = 0.5,\n                                   \n                                   linetype = \"solid\"),\n    \n    legend.background = element_rect(fill = \"#FFFBF0\", \n                                     \n                                     color = \"#FFFBF0\",\n                                     \n                                     linewidth = 0.5,\n                                     \n                                     linetype = \"solid\"),\n    \n    \n    \n    \n    \n  )\n  \n}\n\n\n\n\n\nlongbeach &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-04/longbeach.csv')  \n\n\n\n\n\n# Dogs\n\n\n\n# simple function to merge colours\n\n\n\nsimplify_color &lt;- function(color) {\n  \n  color &lt;- tolower(color)  # Convert to lowercase for consistency\n  \n  \n  \n  case_when(\n    \n    str_detect(color, \"white|cream|silver\") ~ \"White/Silver\",\n    \n    str_detect(color, \"brown|chocolate|tan|fawn|liver\") ~ \"Brown/Tan\",\n    \n    str_detect(color, \"black|seal|black smoke\") ~ \"Black\",\n    \n    str_detect(color, \"gray|blue|blue brindle|blue merle|blue tick\") ~ \"Gray/Blue\",\n    \n    str_detect(color, \"red|ruddy|red merle|orange|apricot\") ~ \"Red/Orange\",\n    \n    str_detect(color, \"yellow|yellow brindle|gold|wheat|blondebuff\") ~ \"Golden\",\n    \n    str_detect(color, \"sable|dapple|brindle|tiger|tricolor\") ~ \"Patterned\",\n    \n    TRUE ~ \"Other\"  # Default category for unexpected values\n    \n  )\n  \n}\n\n\n\n\n\ndogs &lt;- longbeach %&gt;%\n  \n  filter(animal_type == \"dog\") %&gt;%\n  \n  filter(primary_color != \"unknown\" | primary_color != \"pink\") %&gt;%\n  \n  mutate(year = floor(year(as.Date(intake_date))), .after = intake_date) %&gt;%\n  \n  select(animal_type, primary_color, year) %&gt;%\n  \n  mutate(color = simplify_color(primary_color)) %&gt;%\n  \n  select(-c(primary_color))\n\n\n\n\n\ndog_colors &lt;- c(\n  \n  \"White/Silver\" = \"#dcdcdc\",\n  \n  \"Brown/Tan\" = \"#987456\",\n  \n  \"Gray/Blue\" = \"#7e99b4\",\n  \n  \"Golden\" = \"#f7c66b\",\n  \n  \"Black\" = alpha(\"black\",0.75),\n  \n  \"Patterned\" = \"#ffb7c5\",\n  \n  \"Red/Orange\" = \"peru\",\n  \n  \"Other\" = \"#cc3333\"\n  \n  \n  \n)\n\n\n\nsubtitle &lt;- \"The colour of dogs admitted to the Long Beach Animal Shelter over the years\"\n\n\n\np1 &lt;- dogs %&gt;%\n  \n  count(animal_type, color, year) %&gt;%\n  \n  mutate(n = n / 10) %&gt;%\n  \n  ggplot() +\n  \n  geom_waffle0(aes(x = year, y = n, fill = color), gap = 0.015) +\n  \n  scale_x_continuous(breaks = unique(dogs$year)) +  # Ensure all years are displayed\n  \n  scale_fill_manual(values = dog_colors) +\n  \n  Custom_Style() +\n  labs(x = \"Year\", y = \"Count (x10)\", fill = \"Dog Colour\", subtitle = str_wrap(subtitle, 60)) +\n  \n  theme(legend.position = \"right\")\n\n\n#How long pets stay\n\nexcl_animal &lt;- c(\"rabbit\", \"bird\", \"amphibian\", \"wild\", \"other\", \"livestock\")\nadpotion_reasons &lt;- c(\"adoption\", \"return to owner\", \"foster to adopt\")\n\n\ntime &lt;- longbeach %&gt;%\n  \n  filter(!animal_type %in% excl_animal ) %&gt;%\n  filter(outcome_type %in% adpotion_reasons ) %&gt;%\n  \n  \n  select(animal_type, intake_date, outcome_date) %&gt;%\n  \n  mutate(time_in_shelter = outcome_date - intake_date,\n         \n         animal_type = str_to_title(animal_type))\n\n\n\n\n\n\n\nmax_stay &lt;- time %&gt;%\n  \n  group_by(animal_type) %&gt;%\n  \n  summarise(max_time = max(time_in_shelter, na.rm = TRUE))\n\n\n\nsubtitle &lt;- \"Average length of stay for animals in the Long Beach Animal Shelter to being adopted\"\n\n\n\n\n\n# Convert duration to numeric (in days)\n\ntime &lt;- time %&gt;%\n  \n  mutate(time_in_shelter_numeric = as.numeric(time_in_shelter, units = \"days\"))\n\n\n\n# Compute max stay per animal type (in numeric form)\n\nmax_stay &lt;- time %&gt;%\n  \n  group_by(animal_type) %&gt;%\n  \n  summarise(Max_Stay = max(time_in_shelter_numeric, na.rm = TRUE)) %&gt;%\n  \n  rename(\"Type of Animal\" = animal_type,\n         \n         \"Maximum Length of Stay Before Adoption (Days)\" = Max_Stay)\n\n\n\n# Create the violin plot and annotate with table\n\np2 &lt;- ggplot(time, aes(x = time_in_shelter_numeric, y = animal_type, fill = animal_type)) +\n  \n  geom_violin(alpha = 0.8) +\n  \n  scale_x_continuous(limits = c(-10, 365),\n                     \n                     breaks = seq(0, 365, by = 90),\n                     \n                     expand = c(0,0)) +\n  \n  annotate(geom = \"table\", x = 365/2, y = length(max_stay$`Maximum Length of Stay (Days)` ) + 1, label = list(max_stay),\n           \n           vjust = 1, hjust = 0, family = \"Permanent Marker\", color = alpha(\"black\", 0.5),\n           \n           table.theme = ttheme_minimal(\n                                        \n                                        base_colour = \"black\", base_family = \"noto_mono\", color = \"#FFFBF0\",base_size = 14,\n                                        \n                                        core=list(bg_params = list(fill = \"#FFFBF0\")),\n                                        \n                                        colhead = list(bg_params = list(fill = \"#FFFBF0\")))) +\n  \n  labs(x = \"Time Animal is in Shelter (Days)\", y = \"Animal Type\", fill = \"Animal Type\", subtitle = str_wrap(subtitle, 60)) +\n  \n  Custom_Style()\n\n\n\n\n\n\n# Geographcial location\n\nanimal_pickup &lt;- longbeach %&gt;%\n  \n  filter(animal_type == \"dog\" | animal_type == \"cat\") %&gt;% \n  mutate(animal_type = str_to_title(animal_type)) %&gt;% \n  select(animal_type, longitude, latitude) \n\nanimal_sf &lt;- st_as_sf(animal_pickup, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\n\n# Define the long beach boundary (googled)\nlong_beach_bbox &lt;- c(-118.25, 33.75, -118.10, 33.80)\n\n#\nlong_beach_boundary &lt;- opq(bbox = long_beach_bbox) %&gt;%\n  add_osm_feature(key = \"boundary\", value = \"administrative\") %&gt;%\n  add_osm_feature(key = \"name\", value = \"Long Beach\") %&gt;%\n  osmdata_sf() %&gt;%\n  .$osm_multipolygons\n\n\n# Fetch major roads (primary, secondary, and tertiary)\nmajor_roads &lt;- opq(bbox = long_beach_bbox) %&gt;%\n  add_osm_feature(key = \"highway\", \n                  value = c(\"motorway\", \"primary\", \"secondary\", \"tertiary\")) %&gt;%\n  osmdata_sf() %&gt;%\n  .$osm_lines\n\ntitle &lt;- \"Cat and Dog Pickup Locations and Landmarks in Long Beach\"\n\n\np3 &lt;-  ggplot() +\n  geom_sf(data = long_beach_boundary, fill = NA, color = \"black\", size = 1) +\n  geom_sf(data = major_roads, color = \"grey50\", size = 0.8, linetype = \"solid\") +\n  geom_sf(data = animal_sf, aes(color = animal_type), size = 1, alpha = 0.8) +\n  coord_sf(xlim = c(-118.25, -118.10), ylim = c(33.75, 33.80), expand = FALSE) +\n  Custom_Style() +\n  theme(\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank()) +\n  labs(\n       x = \"Longitude\", y = \"Latitude\", subtitle = title, color = \"Animal Type\")\n\ncombined_plot &lt;- (p1 + p2) &\n  theme(legend.position = \"bottom\") &\n  plot_annotation(\n    title = str_wrap('Admittance Data for Long Beach Animal Shelter', 80),\n    subtitle = \"TidyTuesday: Week 9, 2025\",\n    theme = Custom_Style()\n  ) &\n  theme(\n    caption = element_text(hjust = 0.5),\n    plot.subtitle = element_text(size = 16)\n  )\n\nggsave(\n  filename = \"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/thumbnails/TidyTues_Week09a.png\", \n  plot = combined_plot, \n  height = 1080 / 96,  # Converts 1240px to inches (assuming 96 DPI)\n  width = 1920 / 96,    # Converts 1080px to inches\n  dpi = 96,             # Set DPI to 96 to match pixel dimensions\n  units = \"in\",\n)\n\nggsave(\n  filename = \"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/thumbnails/TidyTues_Week09b.png\", \n  plot = p3, \n  height = 400 / 96,  # Converts 1240px to inches (assuming 96 DPI)\n  width = 1920 / 96,    # Converts 1080px to inches\n  dpi = 96,             # Set DPI to 96 to match pixel dimensions\n  units = \"in\",\n)\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week21.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week21.html",
    "title": "TidyTuesday Week 21: Dungeons and Dragons Monsters (2024)",
    "section": "",
    "text": "1. Python code\n\n\nShow code\nimport pandas as pd\nimport plotly.express as px\nimport numpy as np\nimport pyarrow as pa\n\n# Load dataset\nmonsters = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-05-27/monsters.csv')\n\nmonsters[\"Intelligence\"] = monsters[\"int\"] + monsters[\"cha\"] + monsters[\"wis\"]\n\n# Convert to Pandas DataFrame for Plotly\ntop10 = monsters.sort_values(by=\"Intelligence\", ascending=False).head(10)\ntop10 = top10[[\"name\", \"category\", \"str\", \"int\", \"hp_number\", \"Intelligence\"]]\n\ntop10[\"label\"] = top10[\"name\"]\n\n# Create bar chart with dark theme\nfig = px.bar(\n    top10,\n    x=\"Intelligence\",\n    y=\"category\",\n    color=\"category\",\n    orientation=\"h\",\n    text=\"Intelligence\",\n    title=\"Top D&D Monsters by Intelligence Score\",\n    subtitle=\"Intelligence Score is a summation of Charisma, Intelligence, and Wisdom\",  # Note the comma at the end\n    labels={\"Intelligence\": \"Intelligence Score\", \"label\": \"Monster (Type)\"},\n    template=\"plotly_dark\"\n)\n\n# Remove legend and update trace details\nfig.update_layout(\n    showlegend=False,\n    font=dict(\n        family=\"Noto Mono\",\n        size=14,\n        color=\"black\"  # switched to black to contrast with a light background\n    ),\n    paper_bgcolor=\"#FFFBF0\",  # overall page background\n    plot_bgcolor=\"#FFFBF0\"    # plotting area background\n)\nfig.update_traces(textposition=\"outside\", textfont_size=14)\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.show()\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week10.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week10.html",
    "title": "TidyTuesday Week 10: Pixar Films Analysis",
    "section": "",
    "text": "Thumbnail\n\n1. R code\n\nShow code# Load the packages in ----------------------------------------------------\n\nif(!require(httr)){install.packages(\"httr\"); library(httr)}\nif(!require(jsonlite)){install.packages(\"jsonlite\"); library(jsonlite)}\nif(!require(withr)){install.packages(\"withr\"); library(withr)}\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\n\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(gridExtra)){install.packages(\"gridExtra\"); library(gridExtra)}\nif(!require(grid)){install.packages(\"grid\"); library(grid)}\nif(!require(cowplot)){install.packages(\"cowplot\"); library(cowplot)}\nif(!require(showtext)){install.packages(\"showtext\"); library(showtext)}\nif(!require(ggpmisc)){install.packages(\"ggpmisc\"); library(ggpmisc)}\nif(!require(rlist)){install.packages(\"rlist\"); library(rlist)}\n\n# get the wd\nwd &lt;- getwd()\n\n\npixar_films &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-11/pixar_films.csv')\npublic_response &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-11/public_response.csv')\n\n\n\n\nfont_add_google(\"Noto Sans Mono\", \"noto_mono\")\n\nfont &lt;- \"noto_mono\"\n\nshowtext_auto()\n\n\n\n# Color palette\n\ncolor &lt;- palette.colors(palette = \"Okabe-Ito\")\n\ncolor &lt;- append(color, \"gold\")\n\ncolor[1] &lt;- \"#D41159\"\n\n\n\n\n\nCustom_Style &lt;- function() {\n  \n  ggplot2::theme(\n    \n    plot.title = ggplot2::element_text(family=font,\n                                       \n                                       size=24,\n                                       \n                                       face=\"bold\",\n                                       \n                                       color=\"#222222\"),\n    \n    plot.subtitle = ggplot2::element_text(family=font,\n                                          \n                                          size=18,\n                                          \n                                          color=\"#222222\"),\n    \n    plot.caption = ggplot2::element_text(family=font,\n                                         \n                                         size=10,\n                                         \n                                         color=\"#222222\"),\n    \n    \n    \n    legend.position = \"bottom\",\n    \n    legend.title = ggplot2::element_text(family=font,\n                                         \n                                         size=12,\n                                         \n                                         face=\"bold\",\n                                         \n                                         color=\"#222222\"),\n    \n    # legend.text.align = 0,\n    \n    legend.key = ggplot2::element_blank(),\n    \n    legend.text = ggplot2::element_text(family=font,\n                                        \n                                        size=9,\n                                        \n                                        color=\"#222222\"),\n    \n    \n    \n    # Axis format\n    \n    axis.text = ggplot2::element_text(family = font,\n                                      \n                                      size=10,\n                                      \n                                      color=\"#222222\"),\n    \n    axis.text.x = ggplot2::element_text(margin=ggplot2::margin(5, b = 10), size =8),\n    \n    axis.line = ggplot2::element_line(colour = alpha('#222222', 0.5), size =0.5),\n    \n    axis.title = ggplot2::element_text(family=font,\n                                       \n                                       size=12,\n                                       \n                                       face=\"bold\",\n                                       \n                                       color=\"#222222\"),\n    \n    \n    \n    \n    \n    # Grid lines\n    \n    panel.grid.minor = ggplot2::element_blank(),\n    \n    panel.grid.major.y = ggplot2::element_blank(),\n    \n    panel.grid.major.x = ggplot2::element_blank(),\n    \n    \n    \n    \n    \n    \n    \n    # Very pale cream/yellow background\n    \n    panel.background = element_rect(fill = \"#FFFBF0\", \n                                    \n                                    color = \"#FFFBF0\",\n                                    \n                                    linewidth = 0.5,\n                                    \n                                    linetype = \"solid\"),\n    \n    plot.background = element_rect(fill = \"#FFFBF0\", \n                                   \n                                   color = \"#FFFBF0\",\n                                   \n                                   linewidth = 0.5,\n                                   \n                                   linetype = \"solid\"),\n    \n    legend.background = element_rect(fill = \"#FFFBF0\", \n                                     \n                                     color = \"#FFFBF0\",\n                                     \n                                     linewidth = 0.5,\n                                     \n                                     linetype = \"solid\"),\n    \n    \n    \n    \n    \n  )\n  \n}\n\n\n# MAke a Big Dataframe\n\nCombined &lt;- left_join(pixar_films, public_response, by = \"film\") %&gt;% \n  filter(!is.na(metacritic)) %&gt;% \n  mutate(decade = floor(year(as.Date(release_date)) / 10) * 10, .after = release_date) %&gt;% \n  group_by(decade) %&gt;% \n  arrange(release_date) %&gt;% \n  mutate(order_in_decade = row_number(),\n         decade = as.factor(decade)) %&gt;% \n  rename(`Rotten Tomatoes` = rotten_tomatoes,\n         `MetaCritic` = metacritic,\n         `Critics Choice` = critics_choice)\n\n\nrating_columns &lt;- c(\"MetaCritic\", \"Rotten Tomatoes\", \"Critics Choice\")\n\n\nlist_of_plots &lt;- list()\n\nfor (rating in rating_columns) {\n  \n  heatmap_plot &lt;- ggplot(Combined, aes(x = factor(decade), y = order_in_decade, fill = .data[[rating]])) +\n    geom_tile() +\n    scale_x_discrete(limits = sort(unique(Combined$decade))) +\n    geom_text(aes(label = paste0(str_wrap(film, 14), \"\\n\", round(.data[[rating]], 1))),\n              color = alpha(\"Black\", 1), size = 6, family = font) +\n    scale_fill_gradient(low = \"yellow\", high = \"darkgreen\") +\n    labs(\n      subtitle = paste(\"Heatmap of \", str_to_title(rating), \"Ratings\"),\n      x = \"Decade\",\n      y = \"Order in Decade \\n First film in each decade is at the bottom\",\n      fill = paste(str_to_title(rating), \"Rating\")\n    ) +\n    Custom_Style() +\n    theme(legend.position = \"right\")\n\n  list_of_plots &lt;- list.append(list_of_plots, heatmap_plot)\n}\nfinal_patchwork &lt;- wrap_plots(list_of_plots) &\n  theme(legend.position = \"bottom\") &\n  plot_annotation(\n    title = str_wrap('Comparison of Public and Critic Rating Systems for different Pixar films', 80),\n    subtitle = \"TidyTuesday: Week 10, 2025\",\n    theme = Custom_Style()\n  ) &\n  theme(\n    plot.subtitle = element_text(size = 16)\n  )\n\nprint(final_patchwork)\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "biostatistics/Breast_Cancer_KM_plots.html",
    "href": "biostatistics/Breast_Cancer_KM_plots.html",
    "title": "Kaplan Meir Plots in Python",
    "section": "",
    "text": "1. Python code\n\n\nShow code\n# pip install pandas\n# pip install numpy\n# pip install lifelines\n# pip install matplotlib\n\nfrom lifelines import KaplanMeierFitter\nimport pandas as pd \nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\ngbsg2 = pd.read_csv(\"/home/pgr16/Documents/Data_Analysis/German Breast Cancer/GBSG2.csv\")\n\n\n# Create Age Group\n\nbins = [0, 40, 81]\nlabels = [\"0-40\", \"40 and older\"]\n\n\ngbsg2['Age Group'] = pd.cut(gbsg2['age'], bins = bins, labels= labels, right = False)\nkmf = KaplanMeierFitter()\n\nT = gbsg2[\"time\"]\nE = gbsg2[\"cens\"]\n\nkmf.fit(T, event_observed=E)\n\nplt.clf() # clear plot\nkmf.plot_survival_function()\nplt.title(\"Time to Recurrence of German Breast Cancer Patients\")\n\n\nprint(kmf.median_survival_time_)\n\nimport matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\n\nage = (gbsg2[\"Age Group\"] == \"40 and older\")\nplt.clf()\nax = plt.subplot(111)\nkmf = KaplanMeierFitter()\nkmf.fit(T[age], event_observed=E[age], label=\"Over 40 years old\")\nkmf.plot_survival_function(ax=ax)\nkmf.fit(T[~age], event_observed=E[~age], label=\"40 years or younger\")\nkmf.plot_survival_function(ax=ax)\nplt.title(\"Kaplan-Meier Survival Curves by Age Group\")\nplt.xlabel(\"Time (days)\")\nplt.ylabel(\"Survival Probability\")\nplt.legend()\n\n\n\ngrade1 = gbsg2[\"tgrade\"] == \"I\"\ngrade2 = gbsg2[\"tgrade\"] == \"II\"\ngrade3 = gbsg2[\"tgrade\"] == \"III\"\n\nplt.clf()\n\nax = plt.subplot(111)\n\nkmf = KaplanMeierFitter()\n\n# Grade 1\nkmf.fit(T[grade1], event_observed=E[grade1], label=\" Tumor Grade 1\")\nkmf.plot_survival_function(ax=ax, at_risk_counts=True)\n\n\n# Grade 2\nkmf.fit(T[grade2], event_observed=E[grade2], label=\"Tumor Grade 2\")\nkmf.plot_survival_function(ax=ax, at_risk_counts=True)\n\n\n#Grade 3\nkmf.fit(T[grade3], event_observed=E[grade3], label=\"Tumor Grade 3\")\nkmf.plot_survival_function(ax=ax, at_risk_counts=True)\n\n\nplt.title(\"Time to Recurrence by Tumor Grade\")\nplt.xlabel(\"Time (days)\")\nplt.ylabel(\"Survival Probability\")\nplt.legend()\n\n\n1807.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/pandas/tests/indexes/period/test_indexing.html",
    "href": "my-venv/lib/python3.12/site-packages/pandas/tests/indexes/period/test_indexing.html",
    "title": "",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/pandas/tests/indexes/datetimes/test_indexing.html",
    "href": "my-venv/lib/python3.12/site-packages/pandas/tests/indexes/datetimes/test_indexing.html",
    "title": "",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/idna-3.10.dist-info/LICENSE.html",
    "href": "my-venv/lib/python3.12/site-packages/idna-3.10.dist-info/LICENSE.html",
    "title": "",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ‚ÄúAS IS‚Äù AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n\n Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/numpy/random/LICENSE.html",
    "href": "my-venv/lib/python3.12/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ‚ÄúAS IS‚Äù AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm‚Äôs designer. Component licenses are located with the component code.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/werkzeug/debug/shared/ICON_LICENSE.html",
    "href": "my-venv/lib/python3.12/site-packages/werkzeug/debug/shared/ICON_LICENSE.html",
    "title": "",
    "section": "",
    "text": "Silk icon set 1.3 by Mark James mjames@gmail.com\nhttp://www.famfamfam.com/lab/icons/silk/\nLicense: CC-BY-2.5 or CC-BY-3.0\n\n\n\n Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/pooch-1.8.2.dist-info/AUTHORS.html",
    "href": "my-venv/lib/python3.12/site-packages/pooch-1.8.2.dist-info/AUTHORS.html",
    "title": "Project Authors",
    "section": "",
    "text": "Project Authors\nThe following people have made contributions to the project (in alphabetical order by last name) and are considered ‚ÄúThe Pooch Developers‚Äù:\n\nAnderson Banihirwe - The US National Center for Atmospheric Research, USA (ORCID: 0000-0001-6583-571X)\nGenevieve Buckley - Monash University, Australia - (ORCID: 0000-0003-2763-492X)\nLuke Gregor - Environmental Physics, ETH Zurich, Zurich, Switzerland (ORCID: 0000-0001-6071-1857)\nMathias Hauser - Institute for Atmospheric and Climate Science, ETH Zurich, Zurich, Switzerland (ORCID: 0000-0002-0057-4878)\nMark Harfouche - Ramona Optics Inc.¬†- 0000-0002-4657-4603\nDanilo Horta - EMBL-EBI, UK\nHugo van Kemenade - Independent (Non-affiliated) (ORCID: 0000-0001-5715-8632)\nDominic Kempf - Scientific Software Center, Heidelberg University, Germany (ORCID: 0000-0002-6140-2332)\nKacper Kowalik - National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign, USA (ORCID: 0000-0003-1709-3744)\nJohn Leeman\nBj√∂rn Ludwig - Physikalisch-Technische Bundesanstalt, Germany (ORCID: 0000-0002-5910-9137)\nDaniel McCloy - University of Washington, USA (ORCID: 0000-0002-7572-3241)\nJuan Nunez-Iglesias - Monash University, Australia (ORCID: 0000-0002-7239-5828)\nR√©mi Rampin - New York University, USA (ORCID: 0000-0002-0524-2282)\nCl√©ment Robert - Institut de Plan√©tologie et d‚ÄôAstrophysique de Grenoble, France (ORCID: 0000-0001-8629-7068)\nDaniel Shapero - Polar Science Center, University of Washington Applied Physics Lab, USA (ORCID: 0000-0002-3651-0649)\nSantiago Soler - CONICET, Argentina; Instituto Geof√≠sico Sismol√≥gico Volponi, Universidad Nacional de San Juan, Argentina (ORCID: 0000-0001-9202-5317)\nMatthew Turk - University of Illinois at Urbana-Champaign, USA (ORCID: 0000-0002-5294-0198)\nLeonardo Uieda - Universidade de S√£o Paulo, Brazil (ORCID: 0000-0001-6123-9515)\nAntonio Valentino\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "maps.html",
    "href": "maps.html",
    "title": "Maps",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nUK Population\n\n\nMy first foray into GIS work in R visualising the UK population.\n\n\n\n\n\n15 Dec, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLord of the Rings: Scale of Middle Earth\n\n\nA visuaisation of how big Middle Earth is compared with the size of Europe. Sam and Frodo walked a long way! Hobbiton is centered on Cardiff in Wales - just because\n\n\n\n\n\n9 Sep, 2024\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "datavis.html",
    "href": "datavis.html",
    "title": "Data Viz",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 31: British Library Funding\n\n\nThis week we‚Äôre exploring Income Inequality Before and After Taxes, as processed and visualized by Joe Hasell at Our World in Data\n\n\n\n\n\n5 Aug, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 29: British Library Funding\n\n\nThis week we‚Äôre looking into British Library funding!\n\n\n\n\n\n15 Jul, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 28: British Library Funding\n\n\nThis week we‚Äôre looking into British Library funding!\n\n\n\n\n\n15 Jul, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 27: US Petrol Prices\n\n\nIn 2010, the xkcd Color Survey asked hundreds of thousands of people to name colors they saw, revealing the different ways in which people perceive and label colors.\n\n\n\n\n\n8 Jul, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 26: US Petrol Prices\n\n\nThis week we‚Äôre exploring weekly US gas prices! The data comes from the U.S. Energy Information Administration (EIA), which publishes average retail gasoline and diesel prices each Monday. \n\n\n\n\n\n1 Jul, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 25: Measles cases across the world\n\n\nThis week we are exploring measles and rubella cases across the world. This data was downloaded from the World Health Organisation Provisional monthly measles and rubella data on 2025-06-12.\n\n\n\n\n\n24 Jun, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 23: US Judges\n\n\nThis week we‚Äôre exploring U. S. judge data from the {historydata} R package! This dataset contains information about the appointments and careers of all federal judges in United States history since 1789.\n\n\n\n\n\n15 Jun, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 21: Dungeons and Dragons Monsters (2024)\n\n\nThis week we‚Äôre exploring monsters from the Dungeons & Dragons System Reference Document! After the popularity of our Dungeons and Dragons Spells (2024), we thought it might be fun to explore the freely available monsters from the 2024 update.\n\n\n\n\n\n27 May, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 20: Water Quality at Sydney Beaches\n\n\nThis week we‚Äôre exploring the water quality of Sydney‚Äôs iconic beaches. The data is available at the New South Wales State Government Beachwatch website. Beachwatch and our partners monitor water quality at swim sites to ensure that recreational water environments are managed as safely as possible so that as many people as possible can benefit from using the water.\n\n\n\n\n\n20 May, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 19: Seismic Events at Mount Vesuvius\n\n\nThe dataset this week explores seismic events detected at the famous Mount Vesuvius in Italy. It comes from the Italian Istituto Nazionale di Geofisica e Vulcanologia (INGV)‚Äôs Data Portal and can be explored along with other seismic areas on the GOSSIP website. The raw data was saved as individual CSV files from the GOSSIP website and some values were translated from Italian to English.\n\n\n\n\n\n12 May, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 16: Fatal Car Crashes on DST days\n\n\nToday we‚Äôre exploring the (lack of) connection between fatal car crashes in the United States on Daylight Savings Time\n\n\n\n\n\n21 Apr, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 15: Penguins\n\n\nThis week we‚Äôre taking another look at penguins! The Palmer Penguins dataset first appeared in TidyTuesday back in July of 2020. We‚Äôre using the dataset again because, as of R 4.5.0 (released this past Friday), the datasets are available in the base R datasets package!\n\n\n\n\n\n16 Apr, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 14: Timely and Effective Care by US State\n\n\nThis week we‚Äôre exploring state-level results for medicare.gov ‚Äòtimely and effective care‚Äô measurements. As of 2025-04-06, the data is available at the Centers for Medicare and Medicaid Services (CMS) website. Thanks to former TidyTuesday team member Tracy Teal (@tracykteal) for the dataset suggestion and the link to a visualization by Kayla Zhu and Christina Kostandi at the Visual Capitalist.\n\n\n\n\n\n8 Apr, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 13: Pokemon\n\n\nThis week we are exploring Pok√©mon! This dataset is sourced from {pokemon} (CRAN | github), an R package which provides Pok√©mon information in both English and Brazilian Portuguese. I will only be looking at Gen 1 Pok√©mon.\n\n\n\n\n\n30 Mar, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 12: Amazon‚Äôs Annual Reports\n\n\nThis week we‚Äôre exploring text data from Amazon‚Äôs annual reports. The PDFs were read into R using the {pdftools} R package, and explored by TidyTuesday participant Gregory Vander Vinne in a post on his website. Note that stop words (e.g., ‚Äòand‚Äô, ‚Äòthe‚Äô, ‚Äòa‚Äô) have been removed from the data.\n\n\n\n\n\n28 Mar, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 11: Palm Trees Analysis\n\n\nPlant traits are critical to plant form and function ‚Äîincluding growth, survival and reproduction‚Äî and therefore shape fundamental aspects of population and ecosystem dynamics as well as ecosystem services. Here, we present a global species-level compilation of key functional traits for palms (Arecaceae), a plant family with keystone importance in tropical and subtropical ecosystems.\n\n\n\n\n\n19 Mar, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 10: Pixar Films Analysis\n\n\nThis week we‚Äôre exploring Pixar films! The data this week comes from the {pixarfilms} R package by Eric Leung.\n\n\n\n\n\n17 Mar, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 9: Long Beach Animal Shelter\n\n\nThis week we‚Äôre exploring the Long Beach Animal Shelter Data! The dataset comes from the City of Long Beach Animal Care Services via the {animalshelter} R package. This dataset comprises of the intake and outcome record from Long Beach Animal Shelter.\n\n\n\n\n\n4 Mar, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 8: Racial Disparities in US Reproductive Medicine\n\n\nAcademic Literature on Racial and Ethnic Disparities in Reproductive Medicine in the US\n\n\n\n\n\n25 Feb, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 7: FBI Crime Reporting\n\n\nAn analysis of US Law Enforcement Reporting to the National Crime Agency\n\n\n\n\n\n19 Feb, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nRugby Results Web App\n\n\nAn interactive application to analyse the historical results played by the teams of the six nations and the rugby championship\n\n\n\n\n\n17 Feb, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 6: CDC Archive Data Analysis\n\n\nAn Analysis of the CDC datasets archived/purged by the Trump administration\n\n\n\n\n\n11 Feb, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 5: Simpsons Data Analysis\n\n\nAn Analysis of data reagrding the Simpsons TV Series\n\n\n\n\n\n2 Feb, 2025\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/narwhals-1.44.0.dist-info/licenses/LICENSE.html",
    "href": "my-venv/lib/python3.12/site-packages/narwhals-1.44.0.dist-info/licenses/LICENSE.html",
    "title": "",
    "section": "",
    "text": "MIT License\nCopyright (c) 2024, Marco Gorelli\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/pyzmq-27.0.0.dist-info/licenses/LICENSE.html",
    "href": "my-venv/lib/python3.12/site-packages/pyzmq-27.0.0.dist-info/licenses/LICENSE.html",
    "title": "",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2009-2012, Brian Granger, Min Ragan-Kelley\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ‚ÄúAS IS‚Äù AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n\n Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/markdown-3.8.2.dist-info/licenses/LICENSE.html",
    "href": "my-venv/lib/python3.12/site-packages/markdown-3.8.2.dist-info/licenses/LICENSE.html",
    "title": "",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright 2007, 2008 The Python Markdown Project (v. 1.7 and later)\nCopyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b)\nCopyright 2004 Manfred Stienstra (the original version)\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ‚ÄúAS IS‚Äù AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n\n Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/tensorflow/python/ops/distributions/multinomial.html",
    "href": "my-venv/lib/python3.12/site-packages/tensorflow/python/ops/distributions/multinomial.html",
    "title": "",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/pandas/tests/indexes/period/test_constructors.html",
    "href": "my-venv/lib/python3.12/site-packages/pandas/tests/indexes/period/test_constructors.html",
    "title": "",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "my-venv/lib/python3.12/site-packages/seaborn-0.13.2.dist-info/LICENSE.html",
    "href": "my-venv/lib/python3.12/site-packages/seaborn-0.13.2.dist-info/LICENSE.html",
    "title": "",
    "section": "",
    "text": "Copyright (c) 2012-2023, Michael L. Waskom All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ‚ÄúAS IS‚Äù AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n\n Back to top"
  },
  {
    "objectID": "biostatistics/MastersThesis.html",
    "href": "biostatistics/MastersThesis.html",
    "title": "MSc Epidemiology: Thesis",
    "section": "",
    "text": "A copy of my Master‚Äôs Thesis looking at the dynamics of Non-Specific Lower Back Pain Patients in German Emergency Departments.\n\n\n\nDocument"
  },
  {
    "objectID": "biostatistics/MastersThesis.html#masters-thesis",
    "href": "biostatistics/MastersThesis.html#masters-thesis",
    "title": "MSc Epidemiology: Thesis",
    "section": "",
    "text": "A copy of my Master‚Äôs Thesis looking at the dynamics of Non-Specific Lower Back Pain Patients in German Emergency Departments.\n\n\n\nDocument"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week16.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week16.html",
    "title": "TidyTuesday Week 16: Fatal Car Crashes on DST days",
    "section": "",
    "text": "Figure¬†1\n\n\n1. R code\n\nShow code# Load the packages in ----------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(ggplot2)){install.packages(\"ggplot2\"); library(ggplot2)}\nif(!require(sugrrants)){install.packages(\"sugrrants\"); library(sugrrants)}\n# I stick all my styling into a CUsotm PAckage to tidy up my code and keep it consistent over the time\nif(!require(CustomGGPlot2Theme)){devtools::install(\"CustomGGPlot2Theme\"); library(CustomGGPlot2Theme)}\n\n# get the wd - force of habit\nwd &lt;- getwd()\n#pulling images off internet was taking a lot of time and casing a time out error\noptions(timeout = 1000) \n\n\n\nfont &lt;- \"roboto_bold\"\n\ndas &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-22/daily_accidents.csv')\n\ndas &lt;- das %&gt;%\n  mutate(\n    year = lubridate::year(date),\n    date_time = as.POSIXct(date, tz = \"UTC\"), \n    local_time = with_tz(date_time, tzone = \"America/New_York\"),\n    utc_offset = format(local_time, \"%z\")\n  )\n\ndas &lt;- das %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    prev_offset = lag(utc_offset),\n    dst_switch = utc_offset != prev_offset\n  )\n\ndas &lt;- das %&gt;%\n  mutate(\n    dst_change = case_when(\n      is.na(prev_offset) ~ NA_character_,\n      utc_offset &gt; prev_offset ~ \"Forward\",   # Spring: clocks jump ahead\n      utc_offset &lt; prev_offset ~ \"Backward\",  # Fall: clocks go back\n      TRUE ~ NA_character_\n    )\n  )\n\ndst_vs_avg &lt;- das %&gt;%\n  filter(year &gt;= 2010) %&gt;%\n  group_by(year) %&gt;%\n  mutate(avg_fatalities = mean(fatalities_count, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  filter(!is.na(dst_change)) %&gt;%\n  group_by(year, dst_change, avg_fatalities) %&gt;%\n  summarise(\n    dst_fatalities = mean(fatalities_count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    pct_diff = 100 * (dst_fatalities - avg_fatalities) / avg_fatalities\n  )\n\np1 &lt;- ggplot(dst_vs_avg, aes(x = factor(year), y = pct_diff, fill = dst_change)) +\n  geom_col(position = \"dodge\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray40\") +\n  scale_fill_manual(values = c(\"Forward\" = \"steelblue\", \"Backward\" = \"tomato\")) +\n   geom_text(\n    aes(\n      label = paste0(round(pct_diff, digits = 1), \"%\"),\n      #had to do this for dynamic position of the \n      vjust = case_when(pct_diff &gt;= 0 ~ -0.5, TRUE ~ 1.5)\n    ),\n    position = position_dodge(width = 0.9),\n    size = 3.5\n  ) +\n  labs(\n    title = str_wrap(\"Percent Difference in Fatalities on Daylight Savings Change Days (Clocks Forward vs Backward)\", 60),\n    subtitle = \"Compared to annual average fatalities\",\n    x = \"Year\", y = \"% Difference\",\n    fill = \"Clock Change\"\n  ) +\n  Custom_Style() \n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week25.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week25.html",
    "title": "TidyTuesday Week 25: Measles cases across the world",
    "section": "",
    "text": "1. Python code\n\n\nShow code\nimport pandas as pd\nimport plotly.express as px\nimport geopandas as gpd\n\ncases_year = pd.read_csv(\"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/Data/cases_year.csv\")\n\n\neurope = cases_year[cases_year[\"region\"] == \"EURO\"]\n# print(europe[\"country\"].unique())\n#I don;t agree that the stans are part of Europe so I will remove thme\nstans = [\"Azerbaijan\", \"Kazakhstan\", \"Kyrgyzstan\", \"Russian Federation\", \"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\"]\neurope = europe[~europe['country'].isin(stans)]\n\n\nmin_inc = europe['measles_incidence_rate_per_1000000_total_population'].min()\nmax_inc = europe['measles_incidence_rate_per_1000000_total_population'].max()\n\nfig = px.choropleth(\n  europe,\n  locations=\"country\",     # column with country names\n  locationmode=\"country names\",\n  color=\"measles_incidence_rate_per_1000000_total_population\",       # column with measles incidence\n  animation_frame=\"year\",\n  range_color=[min_inc, max_inc],\n  color_continuous_scale=\"Reds\",\n  title=\"Measles Incidence in Europe over Time\",\n  scope=\"europe\",\n  hover_name=\"country\",\n    hover_data={\"measles_incidence_rate_per_1000000_total_population\": True},\n    labels={\"measles_incidence_rate_per_1000000_total_population\": \"Measles Incidence (per 1,000,000)\"}\n)\n\n\nfig.show()\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/Tidy_Tues_Week29.html",
    "href": "data_visualisations/TidyTuesday/2025/Tidy_Tues_Week29.html",
    "title": "TidyTuesday Week 29: British Library Funding",
    "section": "",
    "text": "::: #### 1. Python code\n\n\nShow code\nimport pandas as pd\nimport numpy as np\nimport folium\n\nmta_art = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-22/mta_art.csv')\nstation_lines = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-22/station_lines.csv')\n\n# Extra to get the Long and LAt of NY MTA\n\nstation_locations = pd.read_csv(\"https://data.ny.gov/resource/39hk-dx4f.csv?$query=SELECT%20gtfs_stop_id%2C%20station_id%2C%20complex_id%2C%20division%2C%20line%2C%20stop_name%2C%20borough%2C%20cbd%2C%20daytime_routes%2C%20structure%2C%20gtfs_latitude%2C%20gtfs_longitude%2C%20north_direction_label%2C%20south_direction_label%2C%20ada%2C%20ada_northbound%2C%20ada_southbound%2C%20ada_notes%2C%20georeference\")\n\n\nstation_locations = station_locations[[\"stop_name\", \"gtfs_longitude\", \"gtfs_latitude\"]]\nstation_locations = station_locations.rename(columns={\"stop_name\": \"station_name\", \"gtfs_longitude\": \"longitude\", \"gtfs_latitude\": \"latitude\"})\n\nmaster = mta_art.merge(station_locations, on=\"station_name\", how=\"left\")\n\n\ncenter_lat = master['latitude'].mean()\ncenter_lon = master['longitude'].mean()\n\n\nm = folium.Map(location=[center_lat, center_lon], zoom_start=12)\n\nfor _, row in master.iterrows():\n    lat = row['latitude']\n    lon = row['longitude']\n    station = row['station_name']\n    artwork = row.get('art_title', 'No artwork info')\n    art_link = row.get('art_image_link', None)\n\n    if pd.notnull(lat) and pd.notnull(lon):\n        if pd.notnull(art_link):\n            link_html = f'&lt;a href=\"{art_link}\" target=\"_blank\"&gt;View Artwork&lt;/a&gt;'\n        else:\n            link_html = \"No image link available\"\n\n        popup_html = folium.Popup(\n            f\"\"\"\n            &lt;b&gt;Station:&lt;/b&gt; {station}&lt;br&gt;\n            &lt;b&gt;Artwork:&lt;/b&gt; {artwork}&lt;br&gt;\n            &lt;b&gt;Link:&lt;/b&gt; {link_html}\n            \"\"\",\n            max_width=300\n        )\n\n        folium.Marker(\n            location=[lat, lon],\n            tooltip=f\"Station: {station}\\nArtwork: {artwork}\",  # simpler tooltip for hover\n            popup=popup_html,\n            icon=folium.Icon(color='blue', icon='info-sign')\n        ).add_to(m)\n\nm\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week11.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week11.html",
    "title": "TidyTuesday Week 11: PAlm Trees Analysis",
    "section": "",
    "text": "Thumbnail\n\n1. R code\n\nShow code# Load the packages in ----------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(showtext)){install.packages(\"showtext\"); library(showtext)}\nif(!require(ggdendro)){install.packages(\"ggdendro\"); library(ggdendro)}\nif(!require(ggbrick)){install.packages(\"ggbrick\"); library(ggbrick)}\nif(!require(ggmosaic)){install.packages(\"ggmosaic\"); library(ggmosaic)}\nif(!require(treemapify)){install.packages(\"treemapify\"); library(treemapify)}\n\n# get the wd\nwd &lt;- getwd()\n\n\npalmtrees &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-18/palmtrees.csv')\n\nfont_add_google(\"Noto Sans Mono\", \"noto_mono\")\n\nfont &lt;- \"noto_mono\"\n\nshowtext_auto()\n\n\n\n# Color palette\n\ncolor &lt;- palette.colors(palette = \"Okabe-Ito\")\n\ncolor &lt;- append(color, \"gold\")\n\ncolor[1] &lt;- \"#D41159\"\n\n\n\n\n\nCustom_Style &lt;- function() {\n  \n  ggplot2::theme(\n    \n    plot.title = ggplot2::element_text(family=font,\n                                       \n                                       size=24,\n                                       \n                                       face=\"bold\",\n                                       \n                                       color=\"#222222\"),\n    \n    plot.subtitle = ggplot2::element_text(family=font,\n                                          \n                                          size=18,\n                                          \n                                          color=\"#222222\"),\n    \n    plot.caption = ggplot2::element_text(family=font,\n                                         \n                                         size=10,\n                                         \n                                         color=\"#222222\"),\n    \n    \n    \n    legend.position = \"bottom\",\n    \n    legend.title = ggplot2::element_text(family=font,\n                                         \n                                         size=22,\n                                         \n                                         face=\"bold\",\n                                         \n                                         color=\"#222222\"),\n    \n    # legend.text.align = 0,\n    \n    legend.key = ggplot2::element_blank(),\n    \n    legend.text = ggplot2::element_text(family=font,\n                                        \n                                        size=9,\n                                        \n                                        color=\"#222222\"),\n    \n    \n    \n    # Axis format\n    \n    axis.text = ggplot2::element_text(family = font,\n                                      \n                                      size=10,\n                                      \n                                      color=\"#222222\"),\n    \n    axis.text.x = ggplot2::element_text(margin=ggplot2::margin(5, b = 10), size =8),\n    \n    axis.line = ggplot2::element_line(colour = alpha('#222222', 0.5), size =0.5),\n    \n    axis.title = ggplot2::element_text(family=font,\n                                       \n                                       size=12,\n                                       \n                                       face=\"bold\",\n                                       \n                                       color=\"#222222\"),\n    \n    \n    \n    \n    \n    # Grid lines\n    \n    panel.grid.minor = ggplot2::element_blank(),\n    \n    panel.grid.major.y = ggplot2::element_blank(),\n    \n    panel.grid.major.x = ggplot2::element_blank(),\n    \n    \n    \n    \n    \n    \n    \n    # Very pale cream/yellow background\n    \n    panel.background = element_rect(fill = \"#FFFBF0\", \n                                    \n                                    color = \"#FFFBF0\",\n                                    \n                                    linewidth = 0.5,\n                                    \n                                    linetype = \"solid\"),\n    \n    plot.background = element_rect(fill = \"#FFFBF0\", \n                                   \n                                   color = \"#FFFBF0\",\n                                   \n                                   linewidth = 0.5,\n                                   \n                                   linetype = \"solid\"),\n    \n    legend.background = element_rect(fill = \"#FFFBF0\", \n                                     \n                                     color = \"#FFFBF0\",\n                                     \n                                     linewidth = 0.5,\n                                     \n                                     linetype = \"solid\"),\n    \n    \n    \n    \n    \n  )\n  \n}\npalm_colours &lt;- palmtrees %&gt;%\n  filter(!is.na(main_fruit_colors)) %&gt;% \n  mutate(main_fruit_colors = str_extract(main_fruit_colors, \"^[^;]+\"),\n         main_fruit_colors = str_to_title(main_fruit_colors)) %&gt;% \n  count(palm_tribe, main_fruit_colors) \n\n\n\ncolor_mapping &lt;- c(\n  \"Black\" = alpha(\"black\", 0.7), \"Blue\" = \"blue\", \"Brown\" = \"brown\", \"Green\" = \"green\", \n  \"Orange\" = \"orange\", \"Pink\" = \"pink\", \"Purple\" = \"purple\", \"Red\" = \"red\", \n  \"White\" = \"white\", \"Yellow\" = \"yellow\", \"Cream\" = \"antiquewhite\", \n  \"Grey\" = \"grey\", \"Ivory\" = \"ivory\", \"Straw-Coloured\" = \"wheat\"\n)\n\ncircular_bar &lt;- palm_colours %&gt;% \n  group_by(palm_tribe) %&gt;%\n  mutate(\n    percent = (n / sum(n)) * 100,\n     # Capitalize colors here\n  ) %&gt;%\n  ggplot(aes(x = palm_tribe, y = percent, fill = main_fruit_colors)) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  coord_polar() +\n  \n  scale_fill_manual(values = color_mapping) +\n  labs(fill = \"Primary Fruit Colour\") +\n  Custom_Style() +\n  theme(\n    axis.text.x = element_text(size = 22),\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.line = element_blank(),\n    legend.text = element_text(size = 22)\n  ) +\n  guides(fill = guide_legend(ncol = 3))\n\np1 &lt;- circular_bar +\n  theme(legend.position = \"bottom\") &\n  plot_annotation(\n    title = str_wrap(\"Percentage of Palm Tree Fruit Colors by Tribe\", 60),\n    subtitle = \"TidyTuesday: Week 11, 2025\",\n    theme = Custom_Style()\n  ) &\n  theme(\n    caption = element_text(hjust = 0.5),\n    plot.subtitle = element_text(size = 32),\n    plot.title = element_text(size = 48)\n  )\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week19.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week19.html",
    "title": "TidyTuesday Week 19: Seismic Events at Mount Vesuvius",
    "section": "",
    "text": "1. Python code\n\n\nShow code\nimport pandas as pd\nimport plotly.express as px\n\nvesuvius = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-05-13/vesuvius.csv')\n\n# Data Cleaning\n\n# remove revised\nvesuvius = vesuvius[vesuvius['review_level'] != \"revised\"]\n\n# Remove NAs from longitude and latitude\n\nvesuvius =  vesuvius.dropna(subset = ['latitude', 'longitude', 'duration_magnitude_md'])\n\n# Remove Negative values from magnitude because it was messing with stuff later on\n# Remove earthquakes 0.3 or less so I can further reduce the number and aren't within the margin of error\n\nvesuvius = vesuvius[vesuvius['duration_magnitude_md'] &gt;0.3]\n\n\n# Fix the dates\n\n\n\n\n# split the time column so I can use the date \n\nvesuvius['time'] = pd.to_datetime(vesuvius['time'])\nvesuvius['date'] = vesuvius['time'].dt.date\n\n# 6000 is a lot of earthquakes - lets only from the 2020S\n\nvesuvius = vesuvius[vesuvius['year'] &gt;= 2020]\nmin_mag = vesuvius['duration_magnitude_md'].min()\nmax_mag = vesuvius['duration_magnitude_md'].max()\n\n# Create graph\nfig = px.scatter_mapbox(\n    vesuvius,\n    lat=\"latitude\",\n    lon=\"longitude\",\n    color=\"duration_magnitude_md\",\n    size=\"duration_magnitude_md\",\n    animation_frame=\"date\", \n    color_continuous_scale=\"Viridis\",\n    range_color=[min_mag, max_mag],  # ‚Üê fix color scale\n    size_max=15,\n    zoom=10,\n    center={\"lat\": 40.821, \"lon\": 14.426},\n    mapbox_style=\"carto-positron\",\n    title=\"Earthquake Occurrences in the Vicinity of Mount Vesuvius Over Time &lt;br&gt; (2020‚Äì2024)\",\n    labels={\"duration_magnitude_md\": \"Magnitude (Md)\"}\n)\n\nfig.show()\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week23.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week23.html",
    "title": "TidyTuesday Week 23: US Judges",
    "section": "",
    "text": "1. Python code\n\n\nShow code\n# ! pip install polars\n# ! pip install pandas\n# ! pip install numpy\n# ! pip install folium\n# ! pip install geopy\nimport polars as pl\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.io as pio\nimport matplotlib.pyplot as plt\n\npio.templates.default = 'plotly_white'\n\n\njudges_appointments = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-06-10/judges_appointments.csv')\njudges_people = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-06-10/judges_people.csv')\n\nmerged_df = pd.merge(judges_appointments, judges_people, on = 'judge_id', how = 'left')\nmerged_df[\"commission_date\"] = pd.to_datetime(merged_df[\"commission_date\"], format=\"%m/%d/%Y\")\nmerged_df = merged_df.assign(Non_white = np.where(merged_df[\"race\"] != \"White\", \"Non-White\", \"White\"))\n\n# Top 100  judges per apppointment\n\ntop10 = pd.DataFrame(merged_df.groupby(['president_name']).president_name.value_counts().nlargest(10)).reset_index()\ntop10.columns = ['president_name', 'count']\npio.templates.default = 'plotly_white'\n\n# NUmber of judges per party\nparties = [\"Democratic\", \"Republican\"]\n\nparty = merged_df[merged_df[\"president_party\"].isin(parties)]\nparties = pd.DataFrame(party.groupby(\"president_party\").size()).reset_index()\nparties.columns = ['president_party', 'count']\n\nfig, ax = plt.subplots(figsize=(10, 6)); \nbars = ax.bar(x=top10['president_name'], height=top10['count'], color='skyblue')\nax.set_xlabel('President Name')\nax.set_ylabel('Number of Appointments per President')\nax.set_title('Top 10 Presidents by Number of Appointments')\nax.tick_params(axis='x', rotation=45)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nfor bar in bars:\n    height = bar.get_height()\n    ax.annotate(\n        f'{int(height)}',\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 3),  # Offset above bar\n        textcoords='offset points',\n        ha='center',\n        va='bottom',\n        fontsize=9,\n        color='black'\n    )\n    \n    \nplt.tight_layout()\n\n# By Politcial PArty\nparty_colors = {\n    \"Democratic\": \"blue\",\n    \"Republican\": \"red\"\n}\n\ncolors = parties['president_party'].map(party_colors)\n\n# Create plot\nfig1, ax = plt.subplots(figsize=(10, 6));\nbars = ax.bar(x=parties['president_party'], height=parties['count'], color=colors)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.set_xlabel('Political Party')\nax.set_ylabel('Number of Appointments per Party')\nax.set_title('Number of Appointments by Political Party')\nax.tick_params(axis='x', rotation=0)\n\n# Add count labels on top of bars\nfor bar in bars:\n    height = bar.get_height()\n    ax.annotate(\n        f'{int(height)}',\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 3),\n        textcoords='offset points',\n        ha='center',\n        va='bottom',\n        fontsize=9,\n        color='black'\n    )\n    \nplt.tight_layout()\n\n\nfemale_judge_percent = merged_df.groupby(\"gender\").size()\npercent_df = female_judge_percent.div(female_judge_percent.sum()).mul(100)\n\ndict(\n  value = f\"{round(percent_df.get('F', 0), 1)}%\"\n)\n\n\n\ncut_off = pd.to_datetime(\"1969-01-01\")\n\npre_1968 = merged_df[merged_df[\"commission_date\"] &lt;= cut_off]\n\n\nnon_white_number = pre_1968.groupby(\"Non_white\").size()\nnon_White_percent = non_white_number.div(non_white_number.sum()).mul(100)\n\ndict(\n  value = f\"{round(non_White_percent.get('Non-White', 0), 1)}%\"\n);\n\n\n\n\nrepub = merged_df[merged_df[\"president_party\"].isin([\"Republican\", \"Democratic\"])]\nrepub_number = repub.groupby(\"president_party\").size()\nrepub_percent = repub_number.div(repub_number.sum()).mul(100)\n\ndict(\n  value = f\"{round(repub_percent.get('Republican', 0), 1)}%\"\n);\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week27.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week27.html",
    "title": "TidyTuesday Week 27: US Petrol Prices",
    "section": "",
    "text": "1. Python code\n\n\nShow code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the data\nanswers = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-08/answers.csv')\ncolor_ranks = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-08/color_ranks.csv')\nusers = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-08/users.csv')\n\nmaster = pd.merge(answers, users, on = \"user_id\", how = \"left\")\n\n\nmaster = master[master[\"spam_prob\"] &lt;= 0.5]\n\n\ntop_20_hex_per_monitor = (\n    master.groupby([\"monitor\", \"hex\"])[\"rank\"]\n            .mean()\n            .reset_index()\n            .sort_values([\"monitor\", \"rank\"])\n            .groupby(\"monitor\")\n            .head(20)\n)\n\nfiltered_top = master.merge(\n    top_20_hex_per_monitor[[\"monitor\", \"hex\"]],\n    on=[\"monitor\", \"hex\"]\n)\n\n\ncounts = (\n    filtered_top.groupby([\"monitor\", \"hex\"])\n               .size()\n               .unstack(fill_value=0)\n)\n\n\npercentages = counts.div(counts.sum(axis=1), axis=0) * 100\n\nax = percentages.plot(\n    kind=\"bar\",\n    stacked=True,\n    figsize=(12, 6),\n    colormap=\"tab20\",\n    width=0.8\n)\n\n# Add percentage labels\nfor i, monitor in enumerate(percentages.index):\n    cumulative = 0\n    for hex_code in percentages.columns:\n        value = percentages.loc[monitor, hex_code]\n        if value &gt;= 5:\n            ax.text(\n                i, cumulative + value / 2,\n                f\"{value:.0f}%\",\n                ha=\"center\", va=\"center\", fontsize=8, color=\"black\", rotation=90\n            )\n        cumulative += value\n\n# Formatting\nax.set_ylabel(\"Percentage of Top Colours\")\nax.set_title(\"Top 20 Colours per Monitor (by Frequency)\")\nax.legend(title=\"Hex Colour\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week28.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week28.html",
    "title": "TidyTuesday Week 28: British Library Funding",
    "section": "",
    "text": "British Library Funding\n::: #### 1. R code\n\nShow codeif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(scales)){install.packages(\"scales\"); library(scales)}\nif(!require(CustomGGPlot2Theme)){devtools::install(\"CustomGGPlot2Theme\"); library(CustomGGPlot2Theme)}\n\n\nbl_funding &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-15/bl_funding.csv')\n\n\ngap &lt;-  bl_funding |&gt; \n  select(year,  gia_y2000_gbp_millions, voluntary_y2000_gbp_millions, investment_y2000_gbp_millions, services_y2000_gbp_millions)\n\n\ngap_long &lt;- gap |&gt; \n  pivot_longer(\n    cols = -starts_with(\"year\"),\n    names_to = \"funding_source\",\n    values_to = \"funding\"\n  )    |&gt; \n  mutate(funding_source = case_when(\n    funding_source == \"gia_y2000_gbp_millions\" ~ \"Government\",\n    funding_source == \"voluntary_y2000_gbp_millions\" ~ \"Voluntary\",\n    funding_source == \"investment_y2000_gbp_millions\" ~ \"Investment\",\n    funding_source == \"services_y2000_gbp_millions\" ~ \"Services\",\n    TRUE ~ funding_source\n  ))\n\n\nevents &lt;- data.frame(\n  year = c(2010),\n  event = c(\"Tories voted in\")\n)\n\ngap_plot &lt;- ggplot(gap_long, aes(x = year, y = funding, fill = funding_source)) +\n  geom_area(color = \"black\", size = 0.2, alpha = 0.8) +\n  scale_y_continuous(labels = label_dollar(prefix = \"¬£\")) +\n  labs(\n    title = \"Proportion of British Library Funding by Source)\",\n    x = \"Year\",\n    y = \"Percentage of Total Funding (¬£ millions)\",\n    fill = \"Funding Source\"\n  ) +\n  geom_text(\n    data = events,\n    aes(x = year, y = 105, label = event),\n    angle = 90,\n    vjust = -0.5,\n    hjust = 0,\n    size = 3,\n    inherit.aes = FALSE\n  ) +\n  Custom_Style()  +\n  theme(\n  legend.position = \"right\",\n  text = element_text(size = 10),  \n  axis.title = element_text(size = 10),\n  axis.text = element_text(size = 10),\n  legend.title = element_text(size = 10),\n  legend.text = element_text(size = 10),\n  axis.title.y = element_text(size = 10, margin = margin(r = 10)),\n  plot.title = element_text(size = 10)) +  \n  geom_vline(data = events, aes(xintercept = year), linetype = \"dashed\", color = \"black\") \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week26.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week26.html",
    "title": "TidyTuesday Week 26: US Petrol Prices",
    "section": "",
    "text": "1. Python code\n\n\nShow code\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nimport matplotlib.pyplot as plt\n\n# Load the data\nweekly_gas_prices = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-01/weekly_gas_prices.csv')\n\n# Filter and sort data for regular gasoline\npetrol = weekly_gas_prices[weekly_gas_prices[\"fuel\"] == \"gasoline\"]\npetrol = petrol[petrol[\"grade\"] == \"regular\"]\npetrol = petrol[petrol[\"formulation\"] == \"all\"]\npetrol['date'] = pd.to_datetime(petrol['date'])\npetrol = petrol.sort_values(by=\"date\")\n\n# --- Change for Monthly Aggregation ---\n# Create a 'month_year' column for aggregation\npetrol['month_year'] = petrol['date'].dt.to_period('M')\n\n\nmonthly_petrol = petrol.groupby('month_year')['price'].mean().reset_index()\nmonthly_petrol['month_year'] = monthly_petrol['month_year'].dt.to_timestamp() \n\n\nmonthly_petrol.rename(columns={'month_year': 'date'}, inplace=True)\nmonthly_petrol = monthly_petrol.sort_values(by='date')\n\n\nprices = monthly_petrol[['price']].values\n\nscaler = MinMaxScaler()\nscaled_prices = scaler.fit_transform(prices)\n\ndef create_sequences(data, seq_length):\n    X, y = [], []\n    for i in range(seq_length, len(data)):\n        X.append(data[i-seq_length:i])\n        y.append(data[i])\n    return np.array(X), np.array(y)\n\n\nsequence_length = 36  \nX, y = create_sequences(scaled_prices, sequence_length)\n\nsplit = int(0.8 * len(X))\nX_train, X_test = X[:split], X[split:]\ny_train, y_test = y[:split], y[split:]\n\nmodel = Sequential()\nmodel.add(LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n\nhistory = model.fit(X_train, y_train, epochs=100, batch_size=4, validation_data=(X_test, y_test), verbose=0) \n\npredicted = model.predict(X_test)\npredicted_prices = scaler.inverse_transform(predicted)\nactual_prices = scaler.inverse_transform(y_test)\n\n# plt.figure(figsize=(12, 7))\n# test_dates = monthly_petrol['date'].iloc[split + sequence_length:].reset_index(drop=True)\n# \n# \n# # plt.plot(test_dates, actual_prices, label='Actual Monthly Price')\n# # plt.plot(test_dates, predicted_prices, label='Predicted Monthly Price')\n# # plt.title(\"LSTM Monthly Petrol Price Prediction\")\n# # plt.xlabel(\"Date\")\n# # plt.ylabel(\"Price\")\n# # plt.legend()\n# # plt.grid(True)\n# # plt.show()\n\n# Forecasting\nn_future_months = 24\nlast_sequence = X[-1]  \n\npredicted_sequence = []\ncurrent_seq = last_sequence.copy()\n\nfor _ in range(n_future_months):\n    pred = model.predict(current_seq[np.newaxis, :, :], verbose=0)[0, 0]\n    predicted_sequence.append(pred)\n\n  \n    current_seq = np.append(current_seq[1:], [[pred]], axis=0)\n\npredicted_future_prices = scaler.inverse_transform(np.array(predicted_sequence).reshape(-1, 1))\n\nlast_actual_date = monthly_petrol['date'].max()\n\nfuture_dates = pd.date_range(start=last_actual_date + pd.DateOffset(months=1), periods=n_future_months, freq='MS') # 'MS' for Month Start\n\nplt.figure(figsize=(12, 7))\n\n\nactual_recent_months = monthly_petrol.tail(36)\nplt.plot(actual_recent_months['date'], actual_recent_months['price'], label=\"Actual Monthly Price (Last 24 Months)\")\n\n\nplt.plot(future_dates, predicted_future_prices, label=f\"Forecast (Next {n_future_months} Months)\", color='red', linestyle='--')\n\nplt.title(f\"Monthly Regular Petrol Price Forecast for Next {n_future_months} Months\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Price\")\nplt.legend()\nplt.grid(False)\nplt.show()\n\n\n1/3 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 222ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3/3 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 105ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3/3 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 118ms/step\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week15.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week15.html",
    "title": "TidyTuesday Week 15: Penguins",
    "section": "",
    "text": "(a) Graph done in R\n\n\n\n\n\n\n\n\n\n(b) Graph done in Python\n\n\n\n\n\n\nFigure¬†1: Tidy Tuesday Week 13: Charts\n\n\n1. R code\n\nShow code# Load the packages in ----------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(ggplot2)){install.packages(\"ggplot2\"); library(ggplot2)}\nif(!require(ggwordcloud)){install.packages(\"ggwordcloud\"); library(ggwordcloud)}\nif(!require(ggpmisc)){install.packages(\"ggpmisc\"); library(ggpmisc)}\nif(!require(ggimage)){install.packages(\"ggimage\"); library(ggimage)}\nif(!require(ggtext)){install.packages(\"ggtext\"); library(ggimage)}\nif(!require(rlist)){install.packages(\"rlist\"); library(rlist)}\nif(!require(factoextra)){install.packages(\"factoextra\"); library(factoextra)}\nif(!require(NbClust)){install.packages(\"NbClust\"); library(NbClust)}\n# I stick all my styling into a CUsotm PAckage to tidy up my code and keep it consistent over the time\nif(!require(CustomGGPlot2Theme)){devtools::install(\"CustomGGPlot2Theme\"); library(CustomGGPlot2Theme)}\n\n# get the wd - force of habit\nwd &lt;- getwd()\n#pulling images off internet was taking a lot of time and casing a time out error\noptions(timeout = 1000) \n\n\n\nfont &lt;- \"noto_mono\"\n\npenguins &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins.csv')\n\npenguins_clean &lt;- penguins %&gt;% \n  select(sex, island, bill_len, bill_dep, flipper_len, body_mass) %&gt;% \n  na.omit() %&gt;% \n  mutate(\n    sex = as.numeric(factor(sex)),\n    island = as.numeric(factor(island))\n  )\n\n# Find the optimal number of clusters using elbow method\n# nb &lt;- NbClust(penguins_clean, distance = \"euclidean\", min.nc = 2, max.nc = 10, method = \"kmeans\")\nk &lt;- 2\n\n\nclust_kmeans &lt;- eclust(penguins_clean, k=k, FUNcluster=\"kmeans\", hc_metric=\"euclidean\", graph=FALSE)\nkmeans_silhouette &lt;- fviz_silhouette(clust_kmeans, print.summary = FALSE)\n\nkmeans_graph_2_clusters &lt;- fviz_cluster(clust_kmeans, data = penguins_clean) +\n  Custom_Style() \n\n\n\n#Now lets try with 3 clusters\nk &lt;- 3\n# clust_kmeans &lt;- eclust(penguins_clean, k=k, FUNcluster=\"kmeans\", hc_metric=\"euclidean\", graph=FALSE)\nkmeans_silhouette &lt;- fviz_silhouette(clust_kmeans, print.summary = FALSE)\n\nkmeans_graph_3_clusters &lt;- fviz_cluster(clust_kmeans, data = penguins_clean, labelsize = 0) +\n  Custom_Style() +\n  labs(title = \"K-means Clustering of Penguins (PCA Projection) using R and ggplot2\")\n\n\n2. Python code\n\nShow code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import pairwise_distances_argmin_min\n\nimport requests\n\n\npenguins = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins.csv')\n\npenguins_clean = penguins.replace(\"NaN\", np.nan)  # Replace \"NaN\" text with actual NaN values\npenguins_clean = penguins_clean[[\"sex\", \"island\", \"bill_len\", \"bill_dep\", \"flipper_len\", \"body_mass\"]].dropna()\n\n\nle = LabelEncoder()\npenguins_clean['sex'] = le.fit_transform(penguins_clean['sex']).astype(float)\npenguins_clean['island'] = le.fit_transform(penguins_clean['island']).astype(float)\n\n\n# Just gone straight for 3 now\nk = 3\nkmeans = KMeans(n_clusters = k, random_state = 42)\npenguins_clean['cluster'] = kmeans.fit_predict(penguins_clean)\n\n\npca = PCA(n_components=2)\npca_components = pca.fit_transform(penguins_clean.drop('cluster', axis=1))\npca_df = pd.DataFrame(pca_components, columns=['PC1', 'PC2'])\npca_df['cluster'] = penguins_clean['cluster'].astype(str)\n\n# Plot\n# plt.figure(figsize=(32, 24))\n# # sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='cluster', palette='Set2', s=100)\n# \n# plt.title('K-Means Clustering of Penguins (PCA Projection)')\n# plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_visualisations/TidyTuesday/2025/TidyTues_Week08.html",
    "href": "data_visualisations/TidyTuesday/2025/TidyTues_Week08.html",
    "title": "TidyTuesday Week 8:",
    "section": "",
    "text": "Figure 1\n\n\nDisplay code# gc()\n# rm(list = ls())\n# graphics.off()\n# cat('\\014')\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(ggfortify)){install.packages(\"ggfortify\"); library(ggfortify)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(sysfonts)){install.packages(\"sysfonts\"); library(sysfonts)}\nif(!require(showtext)){install.packages(\"showtext\"); library(showtext)}\nif(!require(RColorBrewer)){install.packages(\"RColorBrewer\"); library(RColorBrewer)}\nif(!require(maps)){install.packages(\"maps\"); library(maps)}\nif(!require(rcrossref)){install.packages(\"rcrossref\"); library(rcrossref)}\n\nwd &lt;- getwd()\n\n\nfont_add_google(\"Roboto Mono\", \"roboto_mono\")\nfont &lt;- \"roboto_mono\"\nshowtext_auto()\n\n# Color palette\ncolor &lt;- palette.colors(palette = \"Okabe-Ito\")\ncolor &lt;- append(color, \"gold\")\ncolor[1] &lt;- \"#D41159\"\n\n\nCustom_Style &lt;- function() {\n  ggplot2::theme(\n    plot.title = ggplot2::element_text(family=font,\n                                       size=24,\n                                       face=\"bold\",\n                                       color=\"#222222\"),\n    plot.subtitle = ggplot2::element_text(family=font,\n                                          size=18,\n                                          color=\"#222222\"),\n    plot.caption = ggplot2::element_text(family=font,\n                                         size=10,\n                                         color=\"#222222\"),\n    \n    legend.position = \"bottom\",\n    legend.title = ggplot2::element_text(family=font, \n                                         size=12, \n                                         face=\"bold\", \n                                         color=\"#222222\"),\n    # legend.text.align = 0,\n    legend.key = ggplot2::element_blank(),\n    legend.text = ggplot2::element_text(family=font,\n                                        size=9,\n                                        color=\"#222222\"),\n    \n    # Axis format\n    axis.text = ggplot2::element_text(family = font,\n                                      size=10,\n                                      color=\"#222222\"),\n    axis.text.x = ggplot2::element_text(margin=ggplot2::margin(5, b = 10), size =8),\n    axis.line = ggplot2::element_line(colour = alpha('#222222', 0.5), size =0.5),\n    axis.title = ggplot2::element_text(family=font, \n                                       size=12, \n                                       face=\"bold\", \n                                       color=\"#222222\"),\n    \n    \n    # Grid lines\n    panel.grid.minor = ggplot2::element_blank(),\n    panel.grid.major.y = ggplot2::element_blank(),\n    panel.grid.major.x = ggplot2::element_blank(),\n    \n    \n    \n    # Very pale cream/yellow background\n    panel.background = element_rect(fill = \"#FFFBF0\",  \n                                    color = \"#FFFBF0\", \n                                    linewidth = 0.5, \n                                    linetype = \"solid\"),\n    plot.background = element_rect(fill = \"#FFFBF0\",  \n                                   color = \"#FFFBF0\", \n                                   linewidth = 0.5, \n                                   linetype = \"solid\"),\n    legend.background = element_rect(fill = \"#FFFBF0\",  \n                                     color = \"#FFFBF0\", \n                                     linewidth = 0.5, \n                                     linetype = \"solid\"),\n    \n    \n  )\n}\n\n\narticle_dat &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-25/article_dat.csv')\nmodel_dat &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-02-25/model_dat.csv')\n\n# Data Cleaning \n\n#Fucntion to simplify races\n\nsimplify_race &lt;- function(race) {\n  case_when(\n    grepl(\"African American|Black|NonBlack, Non-Hispanic Black\", race, ignore.case = TRUE) ~ \"Black\",\n    grepl(\"White|Caucasian|Non-Hispanic White\", race, ignore.case = TRUE) ~ \"White\",\n    grepl(\"Asian\", race, ignore.case = TRUE) ~ \"Asian\",\n    grepl(\"Hispanic|Latino\", race, ignore.case = TRUE) ~ \"Hispanic\",\n    grepl(\"Native American|Alaskan\", race, ignore.case = TRUE) ~ \"Native American\",\n    grepl(\"Pacific Islander|Hawaiian\", race, ignore.case = TRUE) ~ \"Pacific Islander\",\n    grepl(\"Unknown|Other|Multiple\", race, ignore.case = TRUE) ~ \"Other\",\n    TRUE ~ NA\n  )\n}\n\n# function to extract study title from doi using crossref package\n\nget_study_info &lt;- function(doi) {\n  \n  res &lt;- cr_works(doi = doi)\n  \n  if (is.null(res$data)) {\n    return(list(title = NA, first_author = NA))\n  }\n  \n  title &lt;- res$data$title\n  \n  authors &lt;- res$data$author\n  first_author &lt;- if(!is.null(authors) && length(authors) &gt; 0) {\n    \n    authors[[1]]$family\n    \n  } else {\n    \n    NA\n    \n  }\n  \n  doi &lt;-res$data$doi\n  \n  return(list(title = title, first_author = first_author, doi = doi))\n  \n}\n\n# Publications mentioning Race --------------------------------------------\n\n\nrace_count &lt;- article_dat %&gt;% \n  mutate(across(starts_with(c(\"race\", \"eth\")), simplify_race)) %&gt;% \n  rowwise() %&gt;%\n  group_by(across(starts_with(c(\"race\", \"eth\")))) %&gt;% \n  summarise() %&gt;%\n  pivot_longer(cols = everything(), values_to = \"race\") %&gt;% \n  filter(!is.na(race) & race != \"NA\") %&gt;% \n  count(race, sort = TRUE)  \n\np1 &lt;- race_count %&gt;% \n  ggplot(aes(x = reorder(race, n), y = n, fill = race)) +  \n  geom_bar(stat = \"identity\") +  \n  geom_text(aes(label = paste0(\"n = \", n), fontface = \"bold\"), hjust = -0.1, size = 3, angle = 0) +  # Add text labels on top of bars\n  labs(subtitle = str_wrap(\"Race Count Distribution of Reproductive Rights studies in the US (2010-2023)\", 40),\n       x = \"Race\",\n       y = \"Count\",\n       fill = \"Race\") +\n  Custom_Style() +\n  coord_flip()  \n\n\n\n\n\nrace_year_count &lt;- article_dat %&gt;%\n  mutate(across(starts_with(c(\"race\", \"eth\")), simplify_race)) %&gt;%\n  pivot_longer(cols = starts_with(c(\"race\", \"eth\")), values_to = \"race\", names_to = \"race_column\") %&gt;%\n  filter(!is.na(race) & race != \"NA\" & race != \"\") %&gt;%\n  group_by(year, race) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;% \n  group_by(year) %&gt;% \n  mutate(percent = n / sum(n)) %&gt;% \n  arrange(desc(percent)) %&gt;% \n  ungroup()\n\n\n\np2 &lt;- race_year_count %&gt;% \n  ggplot(aes(x = year, y = percent, fill = race)) +  \n  geom_col() +\n  geom_text(aes(label = scales::percent(percent, accuracy = 1), fontface = \"bold\"),  \n            position = position_stack(vjust = 0.5),  \n            size = 3,  \n            family = font,\n            color = \"black\") +  \n  labs(subtitle = str_wrap(\"Proportion of Articles related to Reproductive rights mentioning each race (2010-2023)\", 40),\n       x = \"Race\",\n       y = \"Percent\", fill =\"Race\") +  \n  Custom_Style() +  \n  scale_y_continuous(labels = scales::percent_format())\n\n\n# Combined Plot\n\n\n# Clean the data\n\n\ndata &lt;- model_dat %&gt;%\n  filter(\n    subanalysis == \"No\",\n    measure == \"OR\",          # Ensures reference group includes 'White'\n    !grepl(\"none\", covariates, ignore.case = TRUE),     # Filters out rows where covariates is 'none'\n    outcome == \"severe maternal morbidity\",\n    model_number == 5\n  ) %&gt;% \n  mutate(doi = factor(doi))\n\ndoi &lt;- unique(factor(data$doi))\nd = 1\n\n\ndata_i &lt;- data %&gt;% \n  filter(compare != \"Unknown\") \n\n\ndata_i &lt;- data_i %&gt;%\n  rowwise() %&gt;%\n  mutate(info = list(get_study_info(doi)),\n         citation = paste0(info$first_author[[1]], \" et. al: \", info$doi)) %&gt;% \n  select(-info) \n\nmeasure &lt;- unique(data_i$measure)\nendpoint &lt;- unique(data_i$outcome)\nstudy_title &lt;- unique(data_i$citation)\n\n\n\np3 &lt;- ggplot(data_i, aes(x = point, y = reorder(compare, point))) +  \n  geom_point(size = 3, aes(color = compare)) +  # Points for estimates\n  geom_errorbarh(aes(xmin = lower, xmax = upper, color = compare), height = 0.2) +  # Confidence intervals\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"red\") +  # Reference line at 1\n  labs(subtitle = paste0('Forest Plot: ', str_to_title(endpoint), \" compared with White Women\"),\n       x = paste0(measure, \" (95% CI)\"),\n       y = \"Comparison Group\",\n       color = \"Race\", \n       caption = paste(\"Doi: \", study_title, collapse = \"\\n\")\n  ) +\n  annotate(\"text\", x = 0.5, y = length(unique(data_i$compare)) + 0.5, label = \"Favourable compared with White Women\", color = \"green\", hjust = 0) +\n  annotate(\"text\", x = 1.5, y = length(unique(data_i$compare)) + 0.5, label = \"Outcomes Worsened compared with White Women\", color = \"red\", hjust = 1) +\n  facet_wrap(~ paste(citation, sep = \": \"), labeller = labeller(group = function(x) str_wrap(x, width = 20))) +\n  Custom_Style() +\n  theme(\n    strip.background = element_rect(fill = \"#FFFBF0\", color = \"#FFFBF0\"), # Green background with white border\n    strip.text = element_text(size = 8, face = \"bold\", color = \"black\", family = font, hjust = 0) # White bold text\n  )\n\n\n\n# Combine plots with legend between p1/p2 and p3\ncombined_plot &lt;- (p1 + p2) / \n  p3 +\n  plot_layout(\n    guides = \"collect\"\n  ) &\n  theme(legend.position = \"bottom\") &\n  plot_annotation(\n    title = str_wrap('Academic Literature on Racial and Ethnic Disparities in Reproductive Medicine in the US', 80),\n    subtitle = \"TidyTuesday: Week 8, 2025\",\n    theme = Custom_Style()\n  ) &\n  theme(\n    caption = element_text(hjust = 0.5),\n    plot.subtitle = element_text(size = 16)\n  )\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "I am a statistical programmer with 7 years experience in Pharmaceutical Market Access and Health Economics. I have a Masters Degree in Epidemiology from the Charit√© ‚Äì Universit√§tsmedizin Berlin and a Master‚Äôs in Biomedical Research from Cardiff University.\nI fell into R and Python Programming coupled with data analysis and have kept going with it."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "",
    "section": "",
    "text": "I am a statistical programmer with 7 years experience in Pharmaceutical Market Access and Health Economics. I have a Masters Degree in Epidemiology from the Charit√© ‚Äì Universit√§tsmedizin Berlin and a Master‚Äôs in Biomedical Research from Cardiff University.\nI fell into R and Python Programming coupled with data analysis and have kept going with it."
  },
  {
    "objectID": "index.html#skills-and-interests",
    "href": "index.html#skills-and-interests",
    "title": "",
    "section": "Skills and Interests",
    "text": "Skills and Interests\n\nBiostatistics, R, Python, Data Analysis, Data Visualisation, GIS, Epidemiology, Market Access, Health Economics"
  },
  {
    "objectID": "maps/middle_earth.html",
    "href": "maps/middle_earth.html",
    "title": "Lord of the Rings: Scale of Middle Earth",
    "section": "",
    "text": "#### 1. R code\n\nShow codeif(!require(yaml)){install.packages(\"yaml\"); library(yaml)}\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(ggplot2)){install.packages(\"ggplot2\"); library(ggplot2)}\n# if needed and on Linux apt-get -y update && apt-get install -y  libudunits2-dev libgdal-dev libgeos-dev libproj-dev\nif(!require(sf)){install.packages(\"sf\"); library(sf)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(rnaturalearthdata)){install.packages(\"rnaturalearthdata\"); library(rnaturalearthdata)}\nif(!require(rnaturalearth)){install.packages(\"rnaturalearth\"); library(rnaturalearth)}\nif(!require(ggspatial)){install.packages(\"ggspatial\"); library(ggspatial)}\nif(!require(scales)){install.packages(\"scales\"); library(scales)}\nif(!require(leaflet)){install.packages(\"leaflet\"); library(leaflet)}\nif(!require(glue)){install.packages(\"glue\"); library(glue)}\nif(!require(showtext)){install.packages(\"showtext\"); library(showtext)}\nif(!require(knitr)){install.packages(\"knitr\"); library(knitr)}\nif(!require(ggrepel)){install.packages(\"ggrepel\"); library(ggrepel)}\n\n# Colour Scheme\ncustom_colors &lt;- c(\n  \"#004225\", \"#00007d\", \"#D4A5A5\", \"#1B998B\", \"#F2E86D\", \"#F25F5C\", \"#247BA0\",  \n  \"#662E9B\"\n)\n\n# Custom Theme\ncustom_theme &lt;- function() {\n  ggplot2::theme(\n    plot.title.position   = \"plot\",\n    plot.caption.position = \"plot\",\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5, color = \"#000036\"),\n    axis.title.x = element_text(face = \"bold\", size = 10),\n    axis.title.y = element_text(face = \"bold\", size = 10),\n    panel.border = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(linewidth  = 0.5, colour = \"darkgrey\"),\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10)\n    \n  )\n}\n\n# Custom Fonts \n\nfont_add(family = \"Aniron\", regular = \"/home/pgr16/Documents/Coding/Middle Earth/Fonts/anirm___.ttf\")\nshowtext_auto()\n\nfont_add(family = \"Celtic\", regular = \"/home/pgr16/Documents/Coding/Middle Earth/Fonts/UncialAntiqua-Regular.ttf\")\nshowtext_auto()\n\nworld_map &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/World Countries/ne_50m_admin_0_countries.shp\")\n\ncoastline &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Coastline2.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\ncontours &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Contours_18.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\nrivers &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Rivers.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\nroads &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Roads.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\nlakes &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Lakes.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\nregions &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Regions_Anno.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\nforests &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Forests.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\nmountains &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Mountains_Anno.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\nplacenames &lt;- read_sf(\"/home/pgr16/Documents/Coding/Middle Earth/Middle Earth/Combined_Placenames.shp\") |&gt; \n  mutate(across(where(is.character), ~iconv(., from = \"ISO-8859-1\", to = \"UTF-8\")))\n\nlist &lt;- c(\"Hobbiton\", \"Rivendell\", \"Edoras\", \"Minas Tirith\", \"Bay of Bafalas\", \"Bay of Umbar\", \"Fangorn\", \"Grey Havens\", \"Helm's Deep\", \"Isengard\", \"L√≥rien\", \"Mirkwood\", \"Mt Doom\", \"Sea of Rhun\", \"Mt Doom\")\n\nmiles_to_meters &lt;- function(x) {\n  x * 1609.344\n}\n\nmeters_to_miles &lt;- function(x) {\n  x / 1609.344\n}\n\nclr_green &lt;- \"#035711\"\nclr_blue &lt;- \"#0776e0\"\nclr_yellow &lt;- \"#fffce3\"\n\nhobbiton &lt;- placenames |&gt; \n  filter(NAME == \"Hobbiton\") |&gt; \n  mutate(geometry_x =  map_dbl(geometry, ~as.numeric(.)[1]),\n  geometry_y = map_dbl(geometry, ~as.numeric(.)[2])) |&gt; \n    select(LAYER, NAME, geometry_x, geometry_y)\n\n# Format numeric coordinates with degree symbols and cardinal directions\nformat_coords &lt;- function(coords) {\n  ns &lt;- ifelse(coords[[1]][2] &gt; 0, \"N\", \"S\")\n  ew &lt;- ifelse(coords[[1]][1] &gt; 0, \"E\", \"W\")\n  \n  glue(\"{latitude}¬∞{ns} {longitude}¬∞{ew}\",\n       latitude = sprintf(\"%.6f\", coords[[1]][2]),\n       longitude = sprintf(\"%.6f\", coords[[1]][1]))\n}\n\n\n\neurope_window &lt;- st_sfc(\n  st_point(c(-12.4, 29.31)),  # left (west), bottom (south)\n  st_point(c(44.74, 64.62)),  # right (east), top (north)\n  crs = st_crs(\"EPSG:4326\")   # WGS 84\n) %&gt;% \n  st_transform(crs = st_crs(\"EPSG:5633\")) %&gt;%  # LAEA Europe, centered in Portugal\n  st_coordinates()\n\neurope_plot &lt;- ggplot() +\n  geom_sf(data = world_map, fill = \"#004225\", alpha = 0.5) +\n    coord_sf(crs = st_crs(\"EPSG:5633\"),\n           xlim = europe_window[, \"X\"],\n           ylim = europe_window[, \"Y\"],\n           expand = FALSE) +\n            custom_theme() +\n            labs(\"Map of Europe\")\n\n\ncardiff &lt;- tribble(\n  ~place, ~lat, ~long,\n  \"Cardiff\", 51.481583,  -3.179090\n) %&gt;% \n  st_as_sf(coords = c(\"long\", \"lat\"), crs = st_crs(\"EPSG:4326\")) \n\n# Convert the Tolkien home coordinates to European coordinates\ncardiff &lt;- cardiff %&gt;% \n  st_transform(crs = st_crs(\"EPSG:5633\"))\n\n# Convert the Hobbiton coordinates to European coordinates\n\nhobbiton_in_europe &lt;- hobbiton %&gt;% \n  st_transform(st_crs(\"EPSG:5633\"))\n\n# Find the offset between Tolkien's home and Hobbiton\nme_to_europe &lt;- st_coordinates(cardiff) - st_coordinates(hobbiton_in_europe)\n\nme_places_in_europe &lt;- placenames %&gt;% \n  # Make the Middle Earth data match the Europe projection\n  st_transform(st_crs(\"EPSG:5633\")) %&gt;%\n  # Just look at a handful of places\n  filter(NAME %in% c(\"Hobbiton\", \"Rivendell\", \"Edoras\", \"Minas Tirith\", \"Mt Doom\")) %&gt;% \n  # Double the distances\n  st_set_geometry((st_geometry(.) - st_geometry(hobbiton_in_europe)) * 2 + st_geometry(hobbiton_in_europe)) %&gt;% \n  # Shift everything around so that Hobbiton is in Oxford\n  st_set_geometry(st_geometry(.) + me_to_europe) %&gt;% \n  # All the geometry math made us lose the projection metadata; set it again\n  st_set_crs(st_crs(\"EPSG:5633\"))\n\ncoastline_in_europe &lt;- coastline %&gt;% \n  st_transform(st_crs(\"EPSG:5633\")) %&gt;%\n  st_set_geometry((st_geometry(.) - st_geometry(hobbiton_in_europe)) * 2 + st_geometry(hobbiton_in_europe)) %&gt;% \n  st_set_geometry(st_geometry(.) + me_to_europe) %&gt;% \n  st_set_crs(st_crs(\"EPSG:5633\"))\n\n\neurope_me_plot &lt;- ggplot() + \n  geom_sf(data = world_map, fill = \"#004225\", alpha = 0.5, color = \"white\", linewidth = 0.25) +\n  geom_sf(data = coastline_in_europe, linewidth = 0.25, fill = \"#39CCCC\") +\n  geom_sf(data = me_places_in_europe, fill = \"#39CCCC\", alpha = 0.5) +\n  geom_text_repel(data = filter(me_places_in_europe, NAME %in% list), \n                  aes(label = NAME, geometry = geometry), \n                  stat = \"sf_coordinates\",\n                  nudge_x = -70000, hjust = 1, \n                  family = \"Aniron\", fontface = \"plain\", size = rel(10),\n                  box.padding = 0.5, # Space around labels\n                  point.padding = 0.5, # Space around labeled points\n                  max.overlaps = 10) + # Adjust to control label repulsion\n  coord_sf(crs = st_crs(\"EPSG:5633\"),\n           xlim = europe_window[, \"X\"],\n           ylim = europe_window[, \"Y\"],\n           expand = FALSE) +\n  theme_void() +\n  labs(title = str_wrap(\"Plot of Middle Earth Superimposed over the map of Europe\", 40), \n       subtitle = \"Hobbiton is centred on the great city of Cardiff\") +\n  theme(plot.background = element_rect(fill = clr_yellow),\n        plot.title = element_text(family = \"Aniron\", size = rel(4), hjust = 0.02),\n        plot.subtitle = element_text(family = \"Aniron\", size = rel(2), hjust = 0.02))\n\n\n\n\n\n Back to top"
  }
]