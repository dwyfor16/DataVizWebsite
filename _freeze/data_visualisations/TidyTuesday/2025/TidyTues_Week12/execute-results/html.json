{
  "hash": "b85f90518f95d9e1febc695c4d4e0a64",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"TidyTuesday Week 12: Amazon's Annual Reports\"\nsubtitle: \"This week we're exploring text data from Amazon's annual reports. The PDFs were read into R using the {pdftools} R package, and explored by TidyTuesday participant Gregory Vander Vinne in a post on his website. Note that stop words (e.g., 'and', 'the', 'a') have been removed from the data.\"\nauthor: \"Peter Gray\"\ndate: \"2025-03-28\" \ncategories: [\"TidyTuesday\", \"Data Visualization\", \"R Programming\", \"2025\"]\ntags: [tidytuesday, R, data visulation, ggplot2, patchwork, tidyverse]\nimage: \"thumbnails/TidyTues_Week12.png\"\nformat:\n  html:\n    toc: true\n    toc-depth: 5\n    code-link: true\n    code-fold: true\n    code-tools: false\n    code-summary: \"Show code\"\n    self-contained: true\neditor_options: \n  chunk_output_type: console\nexecute: \n  freeze: true                                                  \n  cache: true                                                   \n  error: false\n  message: false\n  warning: false\n  eval: true\n---\n\n\n![Thumbnail](thumbnails/TidyTues_Week12.png)\n\n#### 1. R code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the packages in ----------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(ggplot2)){install.packages(\"ggplot2\"); library(ggplot2)}\nif(!require(ggwordcloud)){install.packages(\"ggwordcloud\"); library(ggwordcloud)}\n# I stick all my styling into a CUsotm PAckage to tidy up my code and keep it consistent over the time\nif(!require(CustomGGPlot2Theme)){devtools::install(\"CustomGGPlot2Theme\"); library(CustomGGPlot2Theme)}\n\n# get the wd\nwd <- getwd()\n\nfont <- \"noto_mono\"\namazon <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-25/report_words_clean.csv')\n\n\ndata_clean <- amazon %>%\n  filter(year >= 2013) %>%\n  group_by(year, word) %>%\n  summarise(count = n(), .groups = \"drop\") %>%     \n  arrange(year, desc(count)) %>% # Sort within each year by count\n  group_by(year) %>%\n  slice(1:15) %>% # Select top 15 words per year\n  ungroup() %>%\n  filter(word != \"aaa\") %>% \n  mutate(word = str_remove_all(word, \"<.*?>\"))\n\n\n\n\nwordcloud  <- ggplot(data_clean, aes(label = word, size = count, color = count)) +\n  geom_text_wordcloud(area_corr = TRUE) +\n  facet_wrap(~ year) +\n  scale_size_area(max_size = 15) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  Custom_Style() +\n  theme(\n    strip.background = element_rect(fill = \"#FFFBF0\", color = \"#FFFBF0\"), \n    strip.text = element_text(size = 32, face = \"bold\", color = \"black\", family = font, hjust = 0) )\n\np1 <- wordcloud +\n  plot_annotation(\n    title = str_wrap(\"Word Cloud of Top 15 Most Commonly used words in Amazon's Annual Report (2013-2023)\", 40),\n    subtitle = \"TidyTuesday: Week 12, 2025\",\n    theme = Custom_Style()\n  ) &\n  theme(\n    caption = element_text(hjust = 0.5),\n    plot.subtitle = element_text(size = 20),\n    plot.title = element_text(size = 32)\n  )\n\nggsave(\n  filename = \"~/Documents/Coding/Website/data_visualisations/TidyTuesday/2025/thumbnails/TidyTues_Week12.png\", \n  plot = p1, \n  height = 1080 / 96,  # Converts 1240px to inches (assuming 96 DPI)\n  width = 1080 / 96,    # Converts 1080px to inches\n  dpi = 96,             # Set DPI to 96 to match pixel dimensions\n  units = \"in\",\n)\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}