{
  "hash": "6dbfbc134abf8ac02f1207e818755bb0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"TidyTuesday Week 15: Penguins\"\nsubtitle: \"This week we're taking another look at penguins! The Palmer Penguins dataset first appeared in TidyTuesday back in July of 2020. We're using the dataset again because, as of R 4.5.0 (released this past Friday), the datasets are available in the base R datasets package!\"\nauthor: \"Peter Gray\"\ndate: \"2025-04-16\" \ncategories: [\"TidyTuesday\", \"Data Visualization\", \"R Programming\", \"Python\", \"2025\"]\ntags: [tidytuesday, R, data visulation, ggplot2, patchwork, tidyverse, python, seaborn]\nimage: \"thumbnails/TidyTues_Week15a.png\"\nformat:\n  html:\n    toc: true\n    toc-depth: 5\n    code-link: true\n    code-fold: true\n    code-tools: false\n    code-summary: \"Show code\"\n    self-contained: true\neditor_options: \n  chunk_output_type: console\nexecute: \n  freeze: true                                                  \n  cache: true                                                   \n  error: false\n  message: false\n  warning: false\n  eval: true\n---\n\n\n::: {#fig-charts layout-ncol=\"2\"}\n![Graph done in R](thumbnails/TidyTues_Week15a.png){#fig-singlechart}\n\n![Graph done in Python](thumbnails/TidyTues_Week15b.png){#fig-multiplecharts}\n\nTidy Tuesday Week 13: Charts\n:::\n\n#### 1. R code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the packages in ----------------------------------------------------\n\nif(!require(tidyverse)){install.packages(\"tidyverse\"); library(tidyverse)}\nif(!require(patchwork)){install.packages(\"patchwork\"); library(patchwork)}\nif(!require(ggplot2)){install.packages(\"ggplot2\"); library(ggplot2)}\nif(!require(ggwordcloud)){install.packages(\"ggwordcloud\"); library(ggwordcloud)}\nif(!require(ggpmisc)){install.packages(\"ggpmisc\"); library(ggpmisc)}\nif(!require(ggimage)){install.packages(\"ggimage\"); library(ggimage)}\nif(!require(ggtext)){install.packages(\"ggtext\"); library(ggimage)}\nif(!require(rlist)){install.packages(\"rlist\"); library(rlist)}\nif(!require(factoextra)){install.packages(\"factoextra\"); library(factoextra)}\nif(!require(NbClust)){install.packages(\"NbClust\"); library(NbClust)}\n# I stick all my styling into a CUsotm PAckage to tidy up my code and keep it consistent over the time\nif(!require(CustomGGPlot2Theme)){devtools::install(\"CustomGGPlot2Theme\"); library(CustomGGPlot2Theme)}\n\n# get the wd - force of habit\nwd <- getwd()\n#pulling images off internet was taking a lot of time and casing a time out error\noptions(timeout = 1000) \n\n\n\nfont <- \"noto_mono\"\n\npenguins <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins.csv')\n\npenguins_clean <- penguins %>% \n  select(sex, island, bill_len, bill_dep, flipper_len, body_mass) %>% \n  na.omit() %>% \n  mutate(\n    sex = as.numeric(factor(sex)),\n    island = as.numeric(factor(island))\n  )\n\n# Find the optimal number of clusters using elbow method\n# nb <- NbClust(penguins_clean, distance = \"euclidean\", min.nc = 2, max.nc = 10, method = \"kmeans\")\nk <- 2\n\n\nclust_kmeans <- eclust(penguins_clean, k=k, FUNcluster=\"kmeans\", hc_metric=\"euclidean\", graph=FALSE)\nkmeans_silhouette <- fviz_silhouette(clust_kmeans, print.summary = FALSE)\n\nkmeans_graph_2_clusters <- fviz_cluster(clust_kmeans, data = penguins_clean) +\n  Custom_Style() \n\n\n\n#Now lets try with 3 clusters\nk <- 3\n# clust_kmeans <- eclust(penguins_clean, k=k, FUNcluster=\"kmeans\", hc_metric=\"euclidean\", graph=FALSE)\nkmeans_silhouette <- fviz_silhouette(clust_kmeans, print.summary = FALSE)\n\nkmeans_graph_3_clusters <- fviz_cluster(clust_kmeans, data = penguins_clean, labelsize = 0) +\n  Custom_Style() +\n  labs(title = \"K-means Clustering of Penguins (PCA Projection) using R and ggplot2\")\n```\n:::\n\n\n\n#### 2. Python code\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import pairwise_distances_argmin_min\n\nimport requests\n\n\npenguins = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-04-15/penguins.csv')\n\npenguins_clean = penguins.replace(\"NaN\", np.nan)  # Replace \"NaN\" text with actual NaN values\npenguins_clean = penguins_clean[[\"sex\", \"island\", \"bill_len\", \"bill_dep\", \"flipper_len\", \"body_mass\"]].dropna()\n\n\nle = LabelEncoder()\npenguins_clean['sex'] = le.fit_transform(penguins_clean['sex']).astype(float)\npenguins_clean['island'] = le.fit_transform(penguins_clean['island']).astype(float)\n\n\n# Just gone straight for 3 now\nk = 3\nkmeans = KMeans(n_clusters = k, random_state = 42)\npenguins_clean['cluster'] = kmeans.fit_predict(penguins_clean)\n\n\npca = PCA(n_components=2)\npca_components = pca.fit_transform(penguins_clean.drop('cluster', axis=1))\npca_df = pd.DataFrame(pca_components, columns=['PC1', 'PC2'])\npca_df['cluster'] = penguins_clean['cluster'].astype(str)\n\n# Plot\n# plt.figure(figsize=(32, 24))\n# # sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='cluster', palette='Set2', s=100)\n# \n# plt.title('K-Means Clustering of Penguins (PCA Projection)')\n# plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}